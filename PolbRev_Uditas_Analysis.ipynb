{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import itertools\n",
    "import operator\n",
    "import subprocess\n",
    "import twobitreader\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import pysam\n",
    "\n",
    "#not sure if I need these\n",
    "class Error(Exception):\n",
    "    \"\"\"Base class for exceptions in this module.\"\"\"\n",
    "    pass\n",
    "\n",
    "class StrandError(Error):\n",
    "    \"\"\"Exception raised for errors in the strand information.\n",
    "    Attributes:\n",
    "        expression -- input expression in which the error occurred\n",
    "        message -- explanation of the error\n",
    "    \"\"\"\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "\n",
    "class ReactionTypeError(Error):\n",
    "    \"\"\"Exception raised for errors in the reaction type to be processed.\n",
    "    Attributes:\n",
    "        expression -- input expression in which the error occurred\n",
    "        message -- explanation of the error\n",
    "    \"\"\"\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "#### next few window are different inputs to make it run well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#things taken from original uditas args\n",
    "\n",
    "check_plasmid_insertions = 1\n",
    "ncpu = 4\n",
    "window_size = 15\n",
    "amplicon_window_around_cut = 1000\n",
    "min_MAPQ = 5\n",
    "min_AS = -180\n",
    "process_AMP_seq_run = 0 #off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#primer sequences for mispriming. Primer sequence + 12nt downstream \n",
    "#this will only be avialable for read2\n",
    "\n",
    "#polb rev #make sure lettters are capital\n",
    "primer_seq_plus_downstream ='ACAAAAGAGGCCAAGCTGGAGCAGGAAATAGATGC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/edanner/NewUbuntuSpace/Workspace/LinearAmp/Sequence2_191129_MN00157_0047_A000H2GWGF/P_Eric4_BCL2Fastq_only\n"
     ]
    }
   ],
   "source": [
    "#Directory\n",
    "\n",
    "#directory = '/media/edanner/NewUbuntuSpace/Workspace/LinearAmp/Sequence2_191129_MN00157_0047_A000H2GWGF/P_Eric4_BCL2Fastq_only'\n",
    "\n",
    "#this is a minimal directory of only 300 files for quick debugging\n",
    "directory = '/media/edanner/NewUbuntuSpace/Workspace/LinearAmp/Sequence2_191129_MN00157_0047_A000H2GWGF/P_Eric4_BCL2Fastq_only'\n",
    "\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sheets information input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make the 'amplicon_info' list. Taking the line of our experiment csv file\n",
    "\n",
    "def get_csv_data(dir_sample, line_of_data_from_csv):\n",
    "    sample_info_filename = os.path.join(dir_sample, 'sample_info.csv')\n",
    "    experiments = pd.read_csv(sample_info_filename)\n",
    "    return experiments.loc[line_of_data_from_csv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NGS_req-ID                                                                     A000H2GWGF\n",
       "name                                                                        Tn5_Pol50_pbR\n",
       "Sample                                                                               Polb\n",
       "description                                   MiniSeq_K562_PolbHIROS_50per_unsorted_polbR\n",
       "Control sample (Y/N)                                                                    N\n",
       "Notes                                                                                 NaN\n",
       "Dilution                                                                              NaN\n",
       "Cell name_type                                                                       K562\n",
       "UMI_Len                                                                        NNNNNNNNNN\n",
       "IndexI7Primer                                                                      prE369\n",
       "I7_Index_ID                                                          P7_N702_SBS12nextera\n",
       "index_I1                                                                             N702\n",
       "barcode_I1                                                                       CGTACTAG\n",
       "I5_Index_ID                                                              P5_UMI_N50_Tn5-A\n",
       "index_I2                                                                             N501\n",
       "barcode_I2                                                                       GCGATCTA\n",
       "primer1_ForNest                                                                     prE87\n",
       "primer                                                                             prE364\n",
       "genome                                                                               hg38\n",
       "chr                                                                                  chr8\n",
       "start                                                                         4.23504e+07\n",
       "end                                                                           4.23504e+07\n",
       "strand                                                                                  -\n",
       "guide_1                                                                            Polb#3\n",
       "sequence_guide_1                                                     TAATTTTGTGTGGGTCACCC\n",
       "genome_guide_1                                                                       hg38\n",
       "chr_guide_1                                                                          chr8\n",
       "start_guide_1                                                                    42349873\n",
       "end_guide_1                                                                      42349892\n",
       "strand_guide_1                                                                          +\n",
       "guide_2                                                                            Polb#4\n",
       "sequence_guide_2                                                     TGAAACCAGTTTGGTTACCC\n",
       "genome_guide_2                                                                       hg38\n",
       "chr_guide_2                                                                          chr8\n",
       "start_guide_2                                                                    42350280\n",
       "end_guide_2                                                                      42350299\n",
       "strand_guide_2                                                                          +\n",
       "guide_3                                                                               NaN\n",
       "sequence_guide_3                                                                      NaN\n",
       "genome_guide_3                                                                        NaN\n",
       "chr_guide_3                                                                           NaN\n",
       "start_guide_3                                                                         NaN\n",
       "end_guide_3                                                                           NaN\n",
       "strand_guide_3                                                                        NaN\n",
       "Replace_Doner_Name                                                               pE038_MC\n",
       "Replace_Donor                           TGACCCACACAAAATTAGTCTTTTAGCAGACTGGTATGTTTCCAAT...\n",
       "Donor (single strand; double strand)                                                  NaN\n",
       "plamid_name                                                                         pE049\n",
       "plasmid_sequence                        ctatggaaaaacgccagcaacgcggcctttttacggttcctggcct...\n",
       "genomic_background                                                                    NaN\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the amplicon info is related to the line on the csv file. It is indexed from 0. For PolbF we use 0.\n",
    "\n",
    "#1 is because this polbRev \n",
    "amplicon_info = get_csv_data(directory, 1)\n",
    "amplicon_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/edanner/NewUbuntuSpace/Workspace/Ref_Genomes/hg38.2bit\n"
     ]
    }
   ],
   "source": [
    "# Assign the file_genome_2bit location. This is needed for pulling sequence from the referene genome by location\n",
    "assembly = amplicon_info['genome']\n",
    "file_genome_2bit = os.path.join('/media/edanner/NewUbuntuSpace/Workspace/Ref_Genomes', assembly + '.2bit')\n",
    "print(file_genome_2bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BOWTIE2_INDEXES=/media/edanner/NewUbuntuSpace/Workspace/Ref_Genomes\n"
     ]
    }
   ],
   "source": [
    "# BOWTIE2_INDEXES are needed for global alignments\n",
    "#not sure if this will work\n",
    "#normally in bash: export BOWTIE2_INDEXES=/media/edanner/NewUbuntuSpace/Workspace/Ref_Genomes\n",
    "#check in bash: > ECHO $GENOMES_2BIT\n",
    "\n",
    "%env BOWTIE2_INDEXES=/media/edanner/NewUbuntuSpace/Workspace/Ref_Genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the env variables\n",
    "#%env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to process the reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are copied and unchanged from the Uditas v1 software\n",
    "\n",
    "################################################################################\n",
    "# Open .fastq or .fastq.gz files for reading\n",
    "################################################################################\n",
    "def open_fastq_or_gz(filename):\n",
    "    if filename.endswith(\".fastq\") and os.access(filename, os.F_OK):\n",
    "        return open(filename, \"rU\")\n",
    "    elif filename.endswith(\".fastq.gz\") and os.access(filename, os.F_OK):\n",
    "        return gzip.open(filename, \"rb\")\n",
    "    elif filename.endswith(\".fastq\") and os.access(filename + \".gz\", os.F_OK):\n",
    "        return gzip.open(filename + \".gz\", \"rb\")\n",
    "    elif filename.endswith(\".fastq.gz\") and os.access(filename[:-3], os.F_OK):\n",
    "        return open(filename[:-3], \"rU\")\n",
    "    raise IOError(\"Unknown file: \" + filename)\n",
    "\n",
    "################################################################################\n",
    "# Hamming distance\n",
    "# From http://code.activestate.com/recipes/499304-hamming-distance/\n",
    "################################################################################\n",
    "def hamm_dist(str1, str2):\n",
    "    assert len(str1) == len(str2)\n",
    "    ne = operator.ne\n",
    "    return sum(itertools.imap(ne, str1, str2))\n",
    "\n",
    "################################################################################\n",
    "# Select closest barcode with a maximum number of mismatches\n",
    "# By default it returns barcodes with a maximum of n_max_mismatches=2 mismatches\n",
    "################################################################################\n",
    "def select_barcode(seq, barcode_list, n_max_mismatches=1):\n",
    "    # This compares with all barcodes and selects the one with the smallest hamming distance\n",
    "    # Before calling this function check if the sequence is already a barcode\n",
    "    matched_barcodes = list()\n",
    "    distances = list()\n",
    "    for barcode in barcode_list:\n",
    "        h_d = hamm_dist(seq, barcode)\n",
    "        if h_d <= n_max_mismatches:\n",
    "            matched_barcodes.append(barcode)\n",
    "            distances.append(h_d)\n",
    "    indices = [i for i, x in enumerate(distances) if x == min(distances)]\n",
    "    return [matched_barcodes[i] for i in indices]\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Mask sequence by quality score\n",
    "################################################################################\n",
    "def mask(seq, qual, min_qual=12):\n",
    "\n",
    "    return \"\".join((b if (ord(q) - 33) >= min_qual else \"N\") for b, q in itertools.izip(seq, qual))\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# get the reverse-complement DNA sequence\n",
    "################################################################################\n",
    "def reverse_complement(seq):\n",
    "    seq_dict = {'A': 'T', 'T': 'A', 'G': 'C', 'C': 'G', 'N': 'N', 'a': 't', 't': 'a', 'g': 'c', 'c': 'g'}\n",
    "    return \"\".join([seq_dict[base] for base in reversed(seq)])\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Create umi dict\n",
    "################################################################################\n",
    "def create_umi_dict(filename):\n",
    "\n",
    "    umi_file = open_fastq_or_gz(filename)\n",
    "\n",
    "    umi_dict = dict()\n",
    "\n",
    "    umi_reads = itertools.izip(umi_file)\n",
    "\n",
    "    for header_umi in umi_reads:\n",
    "\n",
    "        seq_umi = umi_reads.next()\n",
    "        umi_reads.next()\n",
    "        qual_umi = umi_reads.next()\n",
    "        umi_dict[header_umi[0].split()[0][1:]] = [seq_umi[0].rstrip(), qual_umi[0].rstrip()]\n",
    "\n",
    "    return umi_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################################################################################\n",
    "# create list of output files\n",
    "#I added a bit to allow for the function that makes a fastq of the correctly primed targets\n",
    "################################################################################\n",
    "def create_filename(dir_sample, N7, N5, filetype):\n",
    "    main_folder = os.path.join(dir_sample, N7 + '_' + N5)\n",
    "    if filetype == 'mainfolder':\n",
    "        return main_folder\n",
    "    elif filetype == 'amplicons':\n",
    "        return os.path.join(main_folder, 'amplicons')\n",
    "    elif filetype == 'R1fastq':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R1.fastq')\n",
    "    elif filetype == 'R1fastqgz':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R1.fastq.gz')\n",
    "    elif filetype == 'R2fastq':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R2.fastq')\n",
    "    elif filetype == 'R2fastqgz':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R2.fastq.gz')\n",
    "   \n",
    "    #### I added these as the sequences that were correctly primed\n",
    "    elif filetype == 'R1fastq_CorrPrime':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R1.CorrPrime.fastq')\n",
    "    elif filetype == 'R1fastqgz_CorrPrime':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R1.CorrPrime.fastq.gz')\n",
    "    elif filetype == 'R2fastq_CorrPrime':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R2.CorrPrime.fastq')\n",
    "    elif filetype == 'R2fastqgz_CorrPrime':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R2.CorrPrime.fastq.gz')\n",
    "    #####\n",
    "    \n",
    "    elif filetype == 'umifastq':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_umi.fastq')\n",
    "    elif filetype == 'umifastqgz':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_umi.fastq.gz')\n",
    "    elif filetype == 'R1trimmed':\n",
    "        return os.path.join(main_folder, 'cutadapt_files', N7 + '_' + N5 + '_R1.trimmed.fastq.gz')\n",
    "    elif filetype == 'R2trimmed':\n",
    "        return os.path.join(main_folder, 'cutadapt_files', N7 + '_' + N5 + '_R2.trimmed.fastq.gz')\n",
    "    elif filetype == 'trimmed_report':\n",
    "        return os.path.join(main_folder, 'cutadapt_files', N7 + '_' + N5 + '.trimmed.report.txt')\n",
    "    elif filetype == 'sam_genome_local':\n",
    "        return os.path.join(main_folder, 'sam_genome_local_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_genome_local':\n",
    "        return os.path.join(main_folder, 'sam_genome_local_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_genome_local':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_genome_local':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_genome_local':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'sam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'sam_plasmid_local_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_plasmid_local':\n",
    "        return os.path.join(main_folder, 'sam_plasmid_local_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'unmapped_bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '_unmapped.bam')\n",
    "    elif filetype == 'qsorted_unmapped_bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '_qsorted_unmapped.bam')\n",
    "    elif filetype == 'unmapped_plasmid_R1fastq':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R1.fastq')\n",
    "    elif filetype == 'unmapped_plasmid_R2fastq':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R2.fastq')\n",
    "    elif filetype == 'unmapped_plasmid_R1fastqgz':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R1.fastq.gz')\n",
    "    elif filetype == 'unmapped_plasmid_R2fastqgz':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R2.fastq.gz')\n",
    "    elif filetype == 'sam_amplicons':\n",
    "        return os.path.join(main_folder, 'sam_amplicon_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_amplicons':\n",
    "        return os.path.join(main_folder, 'sam_amplicon_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'unmapped_bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '_amplicons_unmapped.bam')\n",
    "    elif filetype == 'qsorted_unmapped_bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '_qsorted_amplicons_unmapped.bam')\n",
    "    elif filetype == 'unmapped_amplicons_R1fastq':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files', N7 + '_' + N5 + '_amplicons_unmapped_R1.fastq')\n",
    "    elif filetype == 'unmapped_amplicons_R2fastq':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files', N7 + '_' + N5 + '_amplicons_unmapped_R2.fastq')\n",
    "    elif filetype == 'unmapped_amplicons_R1fastqgz':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files',\n",
    "                            N7 + '_' + N5 + '_amplicons_unmapped_R1.fastq.gz')\n",
    "    elif filetype == 'unmapped_amplicons_R2fastqgz':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files',\n",
    "                            N7 + '_' + N5 + '_amplicons_unmapped_R2.fastq.gz')\n",
    "    elif filetype == 'unmapped_amplicons_report':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files', N7 + '_' + N5 + '.unmapped.report.txt')\n",
    "    elif filetype == 'sam_genome_global':\n",
    "        return os.path.join(main_folder, 'sam_genome_global_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_genome_global':\n",
    "        return os.path.join(main_folder, 'sam_genome_global_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_genome_global':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_genome_global':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_genome_global':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'results_amplicons':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5)  # We will append the window size later\n",
    "    elif filetype == 'results_plasmid':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_plasmid.xlsx')\n",
    "    elif filetype == 'results_all_amplicons':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_all_amplicons.xlsx')\n",
    "    elif filetype == 'results_genomewide':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_genomewide.xlsx')\n",
    "    elif filetype == 'summary_all_alignments':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_summary_all_alignments.xlsx')\n",
    "    elif filetype == 'read_counts':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_read_counts.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discard Mispriming Reads\n",
    "When you put a universal primer on the ends of everything, every mispriming event will amplify. An effect we normally don't deal with. I did nested PCR to reduce this. However 85% of the alignments in the UDITAS data I looked at seemed to be mispriming. They did all their blasting and analysis before removing mispriming. But to save computational power and remove error early on I will discard mispriming events. \n",
    "They discard these only for plasmid alignments analyze_alignments_plasmid for some reason which comes from the bam file.\n",
    "\n",
    "By eye it looks like 50-90% of my reads are correctly primed which is amaizng. Nesting helepd a lot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my homemade function to make a fastq with only correct priming events\n",
    "#I currently have skipped making this becasue a relitivly high amount are on target due to nested and I just want results\n",
    "#this should be a similiar function to the demultiplex sorting function but simpler\n",
    "#the sequence to align is the first reads of r2\n",
    "\n",
    "def correct_priming(dir_sample, amplicon_info, primer_seq_plus_downstream):\n",
    "    \n",
    "    #defined the sequence as input (primer and 12 nt downstream). Normally 32-37nt sequence\n",
    "    n_max_mismatches = 3\n",
    "    length_primer_down = len(primer_seq_plus_downstream)\n",
    "    \n",
    "    files_out = list()\n",
    "    n_file = 0\n",
    "    files_out_dict = dict()\n",
    "\n",
    "    for file_selected in files_out:\n",
    "        files_out_dict[os.path.basename(file_selected)] = n_file\n",
    "        n_file += 1\n",
    "    \n",
    "    \n",
    "    #define the input files and output files\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "    \n",
    "    #input files\n",
    "    r1_fastq = create_filename(dir_sample, N7, N5, 'R1fastqgz')\n",
    "    r2_fastq = create_filename(dir_sample, N7, N5, 'R2fastqgz')\n",
    "    \n",
    "    #output files not gz compressed\n",
    "    file_R1_corrprime = create_filename(dir_sample, N7, N5, 'R1fastq_CorrPrime')\n",
    "    file_R2_corrprime = create_filename(dir_sample, N7, N5, 'R2fastq_CorrPrime')\n",
    "\n",
    "    #mismatched files\n",
    "    file_out_r1_not_corrprime = os.path.join(dir_sample, N7 + '_' + N5, 'fastq_files', 'mis_prime_R1.fastq')\n",
    "    file_out_r2_not_corrprime = os.path.join(dir_sample, N7 + '_' + N5, 'fastq_files', 'mis_prime_R2.fastq')\n",
    "\n",
    "    #open/create all these files\n",
    "    ref_file_R1_corrprime = open(file_R1_corrprime, \"w\")\n",
    "    ref_file_R2_corrprime = open(file_R2_corrprime, \"w\")\n",
    "\n",
    "    ref_file_out_r1_not_corrprime = open(file_out_r1_not_corrprime, \"w\")\n",
    "    ref_file_out_r2_not_corrprime = open(file_out_r2_not_corrprime, \"w\")\n",
    "    \n",
    "    file_read_counts = [0] * len(files_out)\n",
    "    \n",
    "    # We open r1,r2 files and distribute reads\n",
    "    with open_fastq_or_gz(r1_fastq) as r1_file, open_fastq_or_gz(r2_fastq) as r2_file:\n",
    "        # Add counters for all reads\n",
    "\n",
    "        reads_in_experiment_list_count = 0\n",
    "\n",
    "        reads_not_in_experiment_list_count = 0\n",
    "\n",
    "        mismatch_count = 0\n",
    "        mismatch_count_r1 = 0\n",
    "        mismatch_count_r2 = 0\n",
    "\n",
    "        mismatch_dict_r1 = dict()\n",
    "        mismatch_dict_r2 = dict()\n",
    " \n",
    "        r1_r2 = itertools.izip(r1_file, r2_file)\n",
    "\n",
    "        for header_r1, header_r2 in r1_r2:\n",
    "    \n",
    "            seq_r1, seq_r2 = r1_r2.next()\n",
    "\n",
    "            r1_r2.next()\n",
    "\n",
    "            qual_r1, qual_r2 = r1_r2.next()\n",
    "\n",
    "            seq_r1, seq_r2 = seq_r1.rstrip(), seq_r2.rstrip()\n",
    "\n",
    "            qual_r1, qual_r2 = qual_r1.rstrip(), qual_r2.rstrip()\n",
    "\n",
    "            #We mask with N any bases with scores below or equal to , (11, default in mask)\n",
    "            \n",
    "            #don't need seq1\n",
    "            #seq_r1_use = mask(seq_r1, qual_r1)\n",
    "\n",
    "            #this is modified for miniseq UMI->Index2\n",
    "            seq_r2_use = mask(seq_r2[:length_primer_down], qual_r2[:length_primer_down])\n",
    "\n",
    "    \n",
    "            # change to 1 for reads with perfect match or match within hamming distance decided above\n",
    "            is_good_read = 0\n",
    "\n",
    "            if seq_r2_use == primer_seq_plus_downstream:\n",
    "                # perfect match case\n",
    "                is_good_read = 1\n",
    "            else:\n",
    "                # We look for barcodes with up to two mismatches, default in select_barcode\n",
    "                h_d = hamm_dist(seq_r2_use, primer_seq_plus_downstream)\n",
    "                if h_d <= n_max_mismatches:\n",
    "                    # match after checking within hamming distance\n",
    "                    is_good_read = 1\n",
    "            \n",
    "                        \n",
    "            #Print good reads \n",
    "            if is_good_read:\n",
    "                # We test whether the read has on of the combination of indices from our experiment list\n",
    "                # If not save in a separate file\n",
    "                r1f = ref_file_R1_corrprime\n",
    "                r2f = ref_file_R2_corrprime\n",
    "\n",
    "                print(\"\\n\".join([header_r1.rstrip(), seq_r1.rstrip(), \"+\", qual_r1.rstrip()]), file=r1f)\n",
    "                print(\"\\n\".join([header_r2.rstrip(), seq_r2.rstrip(), \"+\", qual_r2.rstrip()]), file=r2f)\n",
    "                    \n",
    "                reads_in_experiment_list_count += 1\n",
    "                \n",
    "\n",
    "            else:\n",
    "                # We print reads with mispriming\n",
    "                print(\"\\n\".join([header_r1.rstrip(), seq_r1.rstrip(), \"+\", qual_r1.rstrip()]), file=ref_file_out_r1_not_corrprime)\n",
    "                print(\"\\n\".join([header_r2.rstrip(), seq_r2.rstrip(), \"+\", qual_r2.rstrip()]), file=ref_file_out_r2_not_corrprime)\n",
    "                \n",
    "                reads_not_in_experiment_list_count += 1\n",
    "                \n",
    "        print('reads_in_experiment_list_count', reads_in_experiment_list_count)\n",
    "        print('reads_not_in_experiment_list_count', reads_not_in_experiment_list_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reads_in_experiment_list_count 132279\n",
      "reads_not_in_experiment_list_count 275627\n"
     ]
    }
   ],
   "source": [
    "correct_priming(directory, amplicon_info, primer_seq_plus_downstream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim off illumina adapter from shorter reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#\n",
    "# #this was changed from the uditas original to remove mispriming events\n",
    "#\n",
    "#Remove adapters in fastq files. The idea of this is that if the sequence runs beyond the length of the acutal genomice sequence into the sequencing\n",
    "#       primers on the other other side, it will then be trimmed down so you dont try and align adapter sequences. \n",
    "# Input: directory to be analyzed (fastq files)\n",
    "#        dir_sample, name of the directory for the whole run, typically with the name of a miseq run\n",
    "#        amplicon_info, slice of sample_info.csv for the sample being processed to get the indexes required for saving names\n",
    "#        process_AMP_seq_run, set to 1 to trim in read2 the same adapter as in GUIDE-Seq\n",
    "     # it is very important! to pay attention to if youre using the nextera or trueseq adapters as the sequence to trim will be different on the i7 side.\n",
    "#\n",
    "\n",
    "#\n",
    "# ##########################\n",
    "def trim_fastq(dir_sample, amplicon_info, process_AMP_seq_run=0):\n",
    "\n",
    "    # UDiTaS adapters\n",
    "    Nv2F = 'TCGTCGGCAGCGTCAGATGTGTATAAGAGACAG' #for the i5 side\n",
    "    SBS12nextera = 'GTCTCGTGGGCTCGGAGATGTGTATAAGAGACAG'  #this is for the i7 side for nextera\n",
    "  #  SBS12 = 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'  #this is for i7 side for trueseq primers **need this one for the pytest**\n",
    "\n",
    "    \n",
    "    if process_AMP_seq_run == 1:\n",
    "        #the primer needed for LAM\n",
    "        i2_adapter = 'A'\n",
    "        #i2_adapter = 'ACACTCTTTCCCTACACGACGCTCTTCCGATCT'\n",
    "    else:\n",
    "        i2_adapter = Nv2F\n",
    "\n",
    "    # We first check if the experiment had any guides\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "    \n",
    "    file_R1 = create_filename(dir_sample, N7, N5, 'R1fastq_CorrPrime')\n",
    "    file_R2 = create_filename(dir_sample, N7, N5, 'R2fastq_CorrPrime')\n",
    "\n",
    "    file_cutadapt_R1 = create_filename(dir_sample, N7, N5, 'R1trimmed')\n",
    "    file_cutadapt_R2 = create_filename(dir_sample, N7, N5, 'R2trimmed')\n",
    "    file_cutadapt_report = create_filename(dir_sample, N7, N5, 'trimmed_report')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_cutadapt_R1)):\n",
    "        os.mkdir(os.path.dirname(file_cutadapt_R1))\n",
    "\n",
    "    # remove adapters with cutadapt\n",
    "    #original uditas peramiter had an error -e 0.33 (but was cutting of random stuff too much)\n",
    "    cutadapt_command = ['cutadapt',\n",
    "                        '-m', '10',\n",
    "                        '-e', '0.20',\n",
    "                        '-a', reverse_complement(SBS12nextera),\n",
    "                        '-A', reverse_complement(i2_adapter),\n",
    "                        '-o', file_cutadapt_R1, '-p', file_cutadapt_R2,\n",
    "                        file_R1, file_R2]\n",
    "\n",
    "    handle_cutadapt_report = open(file_cutadapt_report, 'wb')\n",
    "    subprocess.call(cutadapt_command, stdout=handle_cutadapt_report)\n",
    "    handle_cutadapt_report.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the trimming\n",
    "\n",
    "trim_fastq(directory, amplicon_info, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# Function to write reference plasmid sequence\n",
    "################################################\n",
    "def create_plasmid_reference(dir_sample, amplicon_info):\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "    exp_dir = create_filename(dir_sample, N7, N5, 'mainfolder')\n",
    "    amplicon_folder = os.path.join(exp_dir, 'amplicons')\n",
    "    if not os.path.exists(amplicon_folder):\n",
    "        os.mkdir(amplicon_folder)\n",
    "\n",
    "    filename = os.path.join(exp_dir, amplicon_folder, 'plasmid.fa')\n",
    "    file_handle = open(filename, \"w\")\n",
    "\n",
    "    # If several plasmids were given, separate them using ';' in sample_info.csv. Here we remove the ';' so that\n",
    "    # we just concatenate the sequences\n",
    "    pl_seq = amplicon_info['plasmid_sequence'].replace(';', '')\n",
    "    seq1 = Seq(pl_seq, IUPAC.unambiguous_dna)\n",
    "    record1 = SeqRecord(seq1, 'plasmid', description='')\n",
    "    SeqIO.write(record1, file_handle, 'fasta')\n",
    "\n",
    "    file_handle.close()\n",
    "    # Create index file\n",
    "    initial_dir = os.getcwd()\n",
    "    os.chdir(amplicon_folder)\n",
    "    index_err_file = os.path.join(amplicon_folder, 'index_plasmid.err')\n",
    "    index_out_file = os.path.join(amplicon_folder, 'index_plasmid.out')\n",
    "\n",
    "    index_err_fh = open(index_err_file, 'wb')\n",
    "    index_out_fh = open(index_out_file, 'wb')\n",
    "    subprocess.call(['bowtie2-build',\n",
    "                     filename, 'plasmid'], stderr=index_err_fh, stdout=index_out_fh)\n",
    "    os.chdir(initial_dir)\n",
    "    index_err_fh.close()\n",
    "    index_out_fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the reference plasmid creation\n",
    "create_plasmid_reference(directory, amplicon_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ############################\n",
    "    #\n",
    "    #  Function to determine the kind of reaction from the number of cuts and their locations\n",
    "    # I changed this to add the replace option\n",
    "    #\n",
    "    # The function classify the cases:\n",
    "    #   - No cut (just UDiTaS primer, used for controls)\n",
    "    #   - Single cut\n",
    "    #   - Replace (has to come before duel cut in logic order)\n",
    "    #   - Dual cut on same chromosome, generates amplicons with large deletions, etc\n",
    "    #   - Dual cut on different chromosomes. Generates 10 amplicons including translocations\n",
    "    #   - Triple cuts on different chromosomes. Generates 21 amplicons including translocations. NOTE that if two of the\n",
    "    #     cuts are in the same chromosome and close together (less than amplicon_window_around_cut) the results may\n",
    "    #     be incorrect since some reads may be mapped to multiple amplicons, but only counted around the cut in one amplicon\n",
    "    #\n",
    "    ############################\n",
    "    def get_reaction_type(amplicon_info):\n",
    "        has_guide1 = type(amplicon_info['chr_guide_1']) is str or type(amplicon_info['chr_guide_1']) is unicode\n",
    "        has_guide2 = type(amplicon_info['chr_guide_2']) is str or type(amplicon_info['chr_guide_2']) is unicode\n",
    "        has_guide3 = type(amplicon_info['chr_guide_3']) is str or type(amplicon_info['chr_guide_3']) is unicode\n",
    "        has_replace_donor = type(amplicon_info['Replace_Donor']) is str or type(amplicon_info['Replace_Donor']) is unicode\n",
    "    \n",
    "        if not has_guide1 and not has_guide2 and not has_guide3:\n",
    "            reaction_type = 'control'\n",
    "        elif has_guide1 and not has_guide2 and not has_guide3:\n",
    "            reaction_type = 'single_cut'\n",
    "         #this is the modification of the origianl. It shows if we are doing a replace targeting\n",
    "        elif has_guide1 and has_guide2 and amplicon_info['chr_guide_1'] == amplicon_info['chr_guide_2'] and has_replace_donor:\n",
    "            reaction_type = 'replace' \n",
    "        \n",
    "        elif has_guide1 and has_guide2 and amplicon_info['chr_guide_1'] == amplicon_info['chr_guide_2'] and not has_guide3:\n",
    "            reaction_type = 'double_cut_same_chromosome'      \n",
    "        elif has_guide1 and has_guide2 and amplicon_info['chr_guide_1'] != amplicon_info['chr_guide_2'] and not has_guide3:\n",
    "            reaction_type = 'double_cut_different_chromosomes'\n",
    "        elif has_guide1 and has_guide2 and has_guide3:\n",
    "            if (amplicon_info['chr_guide_1'] == amplicon_info['chr_guide_2'] or\n",
    "                    amplicon_info['chr_guide_1'] == amplicon_info['chr_guide_3'] or\n",
    "                    amplicon_info['chr_guide_2'] == amplicon_info['chr_guide_3']):\n",
    "                raise ReactionTypeError('The reaction with three cuts with at least two in the same chromosome is' +\n",
    "                                        ' not yet supported by current version of UDiTaS')\n",
    "            reaction_type = 'triple_cut_different_chromosomes'\n",
    "        else:\n",
    "            raise ReactionTypeError('Reaction type not yet supported by current version of UDiTaS')\n",
    "    \n",
    "        return reaction_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'replace'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test the get_reaction_type is working\n",
    "get_reaction_type(amplicon_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#################################################################################\n",
    "# Function to write reference amplicons with various structural rearrangements\n",
    "#################################################################################\n",
    "def write_amplicon(dir_sample, amplicon_info, amplicon_list):\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "    exp_dir = create_filename(dir_sample, N7, N5, 'mainfolder')\n",
    "    amplicon_folder = os.path.join(exp_dir, 'amplicons')\n",
    "    if not os.path.exists(amplicon_folder):\n",
    "        os.mkdir(amplicon_folder)\n",
    "\n",
    "    filename = os.path.join(exp_dir, amplicon_folder, 'amplicons.fa')\n",
    "    file_handle = open(filename, \"w\")\n",
    "\n",
    "    for amps in amplicon_list:\n",
    "        seq1 = Seq(amps[1], IUPAC.unambiguous_dna)\n",
    "        record1 = SeqRecord(seq1, amps[0], description='')\n",
    "        SeqIO.write(record1, file_handle, 'fasta')\n",
    "\n",
    "    file_handle.close()\n",
    "    # Create index file\n",
    "    initial_dir = os.getcwd()\n",
    "    os.chdir(amplicon_folder)\n",
    "    index_err_file = os.path.join(amplicon_folder, 'index.err')\n",
    "    index_out_file = os.path.join(amplicon_folder, 'index.out')\n",
    "\n",
    "    index_err_fh = open(index_err_file, 'wb')\n",
    "    index_out_fh = open(index_out_file, 'wb')\n",
    "    subprocess.call(['bowtie2-build',\n",
    "                     filename, 'amplicons'], stderr=index_err_fh, stdout=index_out_fh)\n",
    "    os.chdir(initial_dir)\n",
    "    index_err_fh.close()\n",
    "    index_out_fh.close()\n",
    "\n",
    "############################\n",
    "#\n",
    "# Create amplicon. Creates fasta file with the custom reference amplicons including deletions, inversions, etc...\n",
    "#\n",
    "# Input: dir_sample, directory to be analyzed\n",
    "#        amplicon_info, slice of sample_info.csv for the sample being processed\n",
    "#        file_genome_2bit, 2bit file with the reference genome being used\n",
    "#        amplicon_window_around_cut, value used to grab sequences around cut sites\n",
    "#\n",
    "#   This functions creates a set of reference amplicons built from the expected fragments after cutting\n",
    "#   The amplicons are built differently depending on the case classified by get_reaction_type()\n",
    "#\n",
    "# ##########################\n",
    "def create_amplicon(dir_sample, amplicon_info, file_genome_2bit, amplicon_window_around_cut=1000):\n",
    "    # We first check the reaction type\n",
    "    reaction_type = get_reaction_type(amplicon_info)\n",
    "\n",
    "    genome = twobitreader.TwoBitFile(file_genome_2bit)  # Load genome. Used for getting the sequences\n",
    "\n",
    "    amplicon_list = []\n",
    "\n",
    "    # For all reaction types, we check that we don't go out of boundaries when building the amplicons\n",
    "    # This is unlikely for hg38 or mm10, but could easily happen in the UDiTaS primer is in a plasmid\n",
    "    if reaction_type == 'control':\n",
    "        # Case no guides\n",
    "        if amplicon_info['strand'] == '+':  # This is the UDiTaS oligo strand\n",
    "            end_coordinate = int(amplicon_info['start']) + amplicon_window_around_cut\n",
    "            if end_coordinate > len(genome[amplicon_info['chr']]):\n",
    "                end_coordinate = len(genome[amplicon_info['chr']])\n",
    "            amplicon_list.append(['wt', genome[amplicon_info['chr']][int(amplicon_info['start']):end_coordinate]])\n",
    "        elif amplicon_info['strand'] == '-':\n",
    "            start_coordinate = int(amplicon_info['end']) - amplicon_window_around_cut\n",
    "            if start_coordinate < 0:\n",
    "                start_coordinate = 0\n",
    "            amplicon_list.append(['wt', genome[amplicon_info['chr']][start_coordinate:int(amplicon_info['end'])]])\n",
    "        else:\n",
    "            raise StrandError('strand can only have as values + or -')\n",
    "    elif reaction_type == 'single_cut':\n",
    "        # Case one guide\n",
    "        if amplicon_info['strand_guide_1'] == '+':\n",
    "            # sp or sa for the moment only\n",
    "            cut1 = amplicon_info['end_guide_1'] - 3\n",
    "        elif amplicon_info['strand_guide_1'] == '-':\n",
    "            cut1 = amplicon_info['start_guide_1'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_1 can only have as values + or -')\n",
    "\n",
    "        start_coordinate = int(cut1 - amplicon_window_around_cut)\n",
    "        if start_coordinate < 0:\n",
    "            start_coordinate = 0\n",
    "        end_coordinate = int(cut1 + amplicon_window_around_cut)\n",
    "        if end_coordinate > len(genome[amplicon_info['chr_guide_1']]):\n",
    "            end_coordinate = len(genome[amplicon_info['chr_guide_1']])\n",
    "\n",
    "        seq_upstream = genome[amplicon_info['chr_guide_1']][start_coordinate:int(cut1)]\n",
    "        seq_downstream = genome[amplicon_info['chr_guide_1']][int(cut1):end_coordinate]\n",
    "\n",
    "        amplicon_list.append(['wt', seq_upstream + seq_downstream])\n",
    "        amplicon_list.append(['1a_1a', seq_upstream + reverse_complement(seq_upstream)])\n",
    "        amplicon_list.append(['1b_1b', reverse_complement(seq_downstream) + seq_downstream])\n",
    "    elif reaction_type == 'double_cut_same_chromosome':\n",
    "        # Case two guides on the same chromosome\n",
    "        if amplicon_info['strand_guide_1'] == '+':\n",
    "            # sp or sa for the moment only\n",
    "            cut1 = amplicon_info['end_guide_1'] - 3\n",
    "        elif amplicon_info['strand_guide_1'] == '-':\n",
    "            cut1 = amplicon_info['start_guide_1'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_1 can only have as values + or -')\n",
    "\n",
    "        if amplicon_info['strand_guide_2'] == '+':\n",
    "            cut2 = amplicon_info['end_guide_2'] - 3\n",
    "        elif amplicon_info['strand_guide_2'] == '-':\n",
    "            cut2 = amplicon_info['start_guide_2'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_2 can only have as values + or -')\n",
    "\n",
    "        # We switch the coordinates of cut1 and cut2 if the guides are provided so that cut2 < cut1\n",
    "        # cut1 it will always be smaller than cut2 and in the results cut1 will be the cut site with\n",
    "        # smaller genomic coordinate\n",
    "        # cut1 and cut2 also flipped in get_cut_in_reference_amplicon_df\n",
    "\n",
    "        if cut2 < cut1:\n",
    "            (cut1, cut2) = (cut2, cut1)\n",
    "\n",
    "        start_coordinate = int(cut1 - amplicon_window_around_cut)\n",
    "        if start_coordinate < 0:\n",
    "            start_coordinate = 0\n",
    "        end_coordinate = int(cut2 + amplicon_window_around_cut)\n",
    "        if end_coordinate > len(genome[amplicon_info['chr_guide_1']]):\n",
    "            end_coordinate = len(genome[amplicon_info['chr_guide_1']])\n",
    "\n",
    "        seq_upstream = genome[amplicon_info['chr_guide_1']][start_coordinate:int(cut1)]\n",
    "        seq_cut1_cut2 = genome[amplicon_info['chr_guide_1']][int(cut1):int(cut2)]\n",
    "        seq_downstream = genome[amplicon_info['chr_guide_1']][int(cut2):end_coordinate]\n",
    "\n",
    "        amplicon_list.append(['wt', seq_upstream + seq_cut1_cut2 + seq_downstream])\n",
    "        amplicon_list.append(['large_deletion', seq_upstream + seq_downstream])\n",
    "        amplicon_list.append(['large_inversion', seq_upstream + reverse_complement(seq_cut1_cut2) + seq_downstream])\n",
    "        amplicon_list.append(['1a_1a', seq_upstream + reverse_complement(seq_upstream)])\n",
    "        amplicon_list.append(['2b_2b', reverse_complement(seq_downstream) + seq_downstream])\n",
    "    \n",
    "    #added this modification from Uditas for replace\n",
    "    elif reaction_type == 'replace':\n",
    "        if amplicon_info['strand_guide_1'] == '+':\n",
    "            # sp or sa for the moment only\n",
    "            cut1 = amplicon_info['end_guide_1'] - 3\n",
    "        elif amplicon_info['strand_guide_1'] == '-':\n",
    "            cut1 = amplicon_info['start_guide_1'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_1 can only have as values + or -')\n",
    "\n",
    "        if amplicon_info['strand_guide_2'] == '+':\n",
    "            cut2 = amplicon_info['end_guide_2'] - 3\n",
    "        elif amplicon_info['strand_guide_2'] == '-':\n",
    "            cut2 = amplicon_info['start_guide_2'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_2 can only have as values + or -')\n",
    "\n",
    "        # We switch the coordinates of cut1 and cut2 if the guides are provided so that cut2 < cut1\n",
    "        # cut1 it will always be smaller than cut2 and in the results cut1 will be the cut site with\n",
    "        # smaller genomic coordinate\n",
    "        # cut1 and cut2 also flipped in get_cut_in_reference_amplicon_df\n",
    "\n",
    "        if cut2 < cut1:\n",
    "            (cut1, cut2) = (cut2, cut1)\n",
    "\n",
    "        start_coordinate = int(cut1 - amplicon_window_around_cut)\n",
    "        if start_coordinate < 0:\n",
    "            start_coordinate = 0\n",
    "        end_coordinate = int(cut2 + amplicon_window_around_cut)\n",
    "        if end_coordinate > len(genome[amplicon_info['chr_guide_1']]):\n",
    "            end_coordinate = len(genome[amplicon_info['chr_guide_1']])\n",
    "\n",
    "        seq_upstream = genome[amplicon_info['chr_guide_1']][start_coordinate:int(cut1)]\n",
    "        seq_cut1_cut2 = genome[amplicon_info['chr_guide_1']][int(cut1):int(cut2)]\n",
    "        seq_downstream = genome[amplicon_info['chr_guide_1']][int(cut2):end_coordinate]\n",
    "\n",
    "        amplicon_list.append(['wt', seq_upstream + seq_cut1_cut2 + seq_downstream])\n",
    "        amplicon_list.append(['large_deletion', seq_upstream + seq_downstream])\n",
    "        amplicon_list.append(['large_inversion', seq_upstream + reverse_complement(seq_cut1_cut2) + seq_downstream])\n",
    "        amplicon_list.append(['replace_fwd', seq_upstream + amplicon_info['Replace_Donor'] + seq_downstream])\n",
    "        amplicon_list.append(['replace_rev', seq_upstream + reverse_complement(amplicon_info['Replace_Donor']) + seq_downstream])\n",
    "        amplicon_list.append(['doner_tail_tail', amplicon_info['Replace_Donor'] + reverse_complement(amplicon_info['Replace_Donor'])])\n",
    "        amplicon_list.append(['doner_head_tail', amplicon_info['Replace_Donor'] + amplicon_info['Replace_Donor']])\n",
    "        amplicon_list.append(['doner_head_head', reverse_complement(amplicon_info['Replace_Donor']) + amplicon_info['Replace_Donor']])      \n",
    "        amplicon_list.append(['1a_1a', seq_upstream + reverse_complement(seq_upstream)])\n",
    "        amplicon_list.append(['2b_2b', reverse_complement(seq_downstream) + seq_downstream])\n",
    "        \n",
    "        \n",
    "    elif reaction_type == 'double_cut_different_chromosomes':\n",
    "        # Case two guides on different chromosomes\n",
    "        if amplicon_info['strand_guide_1'] == '+':\n",
    "            # sp or sa for the moment only\n",
    "            cut1 = amplicon_info['end_guide_1'] - 3\n",
    "        elif amplicon_info['strand_guide_1'] == '-':\n",
    "            cut1 = amplicon_info['start_guide_1'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_1 can only have as values + or -')\n",
    "\n",
    "        if amplicon_info['strand_guide_2'] == '+':\n",
    "            cut2 = amplicon_info['end_guide_2'] - 3\n",
    "        elif amplicon_info['strand_guide_2'] == '-':\n",
    "            cut2 = amplicon_info['start_guide_2'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_2 can only have as values + or -')\n",
    "\n",
    "        start_coordinate1 = int(cut1 - amplicon_window_around_cut)\n",
    "        if start_coordinate1 < 0:\n",
    "            start_coordinate1 = 0\n",
    "        end_coordinate1 = int(cut1 + amplicon_window_around_cut)\n",
    "        if end_coordinate1 > len(genome[amplicon_info['chr_guide_1']]):\n",
    "            end_coordinate1 = len(genome[amplicon_info['chr_guide_1']])\n",
    "\n",
    "        start_coordinate2 = int(cut2 - amplicon_window_around_cut)\n",
    "        if start_coordinate2 < 0:\n",
    "            start_coordinate2 = 0\n",
    "        end_coordinate2 = int(cut2 + amplicon_window_around_cut)\n",
    "        if end_coordinate2 > len(genome[amplicon_info['chr_guide_2']]):\n",
    "            end_coordinate2 = len(genome[amplicon_info['chr_guide_2']])\n",
    "\n",
    "        seq_1a = genome[amplicon_info['chr_guide_1']][start_coordinate1:int(cut1)]\n",
    "        seq_1b = genome[amplicon_info['chr_guide_1']][int(cut1):end_coordinate1]\n",
    "        seq_2a = genome[amplicon_info['chr_guide_2']][start_coordinate2:int(cut2)]\n",
    "        seq_2b = genome[amplicon_info['chr_guide_2']][int(cut2):end_coordinate2]\n",
    "\n",
    "        amplicon_list.append(['1a_1a', seq_1a + reverse_complement(seq_1a)])\n",
    "        amplicon_list.append(['1a_1b', seq_1a + seq_1b])\n",
    "        amplicon_list.append(['1a_2a', seq_1a + reverse_complement(seq_2a)])\n",
    "        amplicon_list.append(['1a_2b', seq_1a + seq_2b])\n",
    "\n",
    "        amplicon_list.append(['1b_1b', reverse_complement(seq_1b) + seq_1b])\n",
    "        amplicon_list.append(['2a_1b', seq_2a + seq_1b])\n",
    "        amplicon_list.append(['2b_1b', reverse_complement(seq_2b) + seq_1b])\n",
    "\n",
    "        amplicon_list.append(['2a_2a', seq_2a + reverse_complement(seq_2a)])\n",
    "        amplicon_list.append(['2a_2b', seq_2a + seq_2b])\n",
    "\n",
    "        amplicon_list.append(['2b_2b', reverse_complement(seq_2b) + seq_2b])\n",
    "    elif reaction_type == 'triple_cut_different_chromosomes':\n",
    "        # Case three guides on different chromosomes\n",
    "\n",
    "        if amplicon_info['strand_guide_1'] == '+':\n",
    "            # sp or sa for the moment only\n",
    "            cut1 = amplicon_info['end_guide_1'] - 3\n",
    "        elif amplicon_info['strand_guide_1'] == '-':\n",
    "            cut1 = amplicon_info['start_guide_1'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_1 can only have as values + or -')\n",
    "\n",
    "        if amplicon_info['strand_guide_2'] == '+':\n",
    "            cut2 = amplicon_info['end_guide_2'] - 3\n",
    "        elif amplicon_info['strand_guide_2'] == '-':\n",
    "            cut2 = amplicon_info['start_guide_2'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_2 can only have as values + or -')\n",
    "\n",
    "        if amplicon_info['strand_guide_3'] == '+':\n",
    "            cut3 = amplicon_info['end_guide_3'] - 3\n",
    "        elif amplicon_info['strand_guide_3'] == '-':\n",
    "            cut3 = amplicon_info['start_guide_3'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_3 can only have as values + or -')\n",
    "\n",
    "        start_coordinate1 = int(cut1 - amplicon_window_around_cut)\n",
    "        if start_coordinate1 < 0:\n",
    "            start_coordinate1 = 0\n",
    "        end_coordinate1 = int(cut1 + amplicon_window_around_cut)\n",
    "        if end_coordinate1 > len(genome[amplicon_info['chr_guide_1']]):\n",
    "            end_coordinate1 = len(genome[amplicon_info['chr_guide_1']])\n",
    "\n",
    "        start_coordinate2 = int(cut2 - amplicon_window_around_cut)\n",
    "        if start_coordinate2 < 0:\n",
    "            start_coordinate2 = 0\n",
    "        end_coordinate2 = int(cut2 + amplicon_window_around_cut)\n",
    "        if end_coordinate2 > len(genome[amplicon_info['chr_guide_2']]):\n",
    "            end_coordinate2 = len(genome[amplicon_info['chr_guide_2']])\n",
    "\n",
    "        start_coordinate3 = int(cut3 - amplicon_window_around_cut)\n",
    "        if start_coordinate3 < 0:\n",
    "            start_coordinate3 = 0\n",
    "        end_coordinate3 = int(cut3 + amplicon_window_around_cut)\n",
    "        if end_coordinate3 > len(genome[amplicon_info['chr_guide_3']]):\n",
    "            end_coordinate3 = len(genome[amplicon_info['chr_guide_3']])\n",
    "\n",
    "        seq_1a = genome[amplicon_info['chr_guide_1']][start_coordinate1:int(cut1)]\n",
    "        seq_1b = genome[amplicon_info['chr_guide_1']][int(cut1):end_coordinate1]\n",
    "        seq_2a = genome[amplicon_info['chr_guide_2']][start_coordinate2:int(cut2)]\n",
    "        seq_2b = genome[amplicon_info['chr_guide_2']][int(cut2):end_coordinate2]\n",
    "        seq_3a = genome[amplicon_info['chr_guide_3']][start_coordinate3:int(cut3)]\n",
    "        seq_3b = genome[amplicon_info['chr_guide_3']][int(cut3):end_coordinate3]\n",
    "\n",
    "        amplicon_list.append(['1a_1a', seq_1a + reverse_complement(seq_1a)])\n",
    "        amplicon_list.append(['1a_1b', seq_1a + seq_1b])\n",
    "        amplicon_list.append(['1a_2a', seq_1a + reverse_complement(seq_2a)])\n",
    "        amplicon_list.append(['1a_2b', seq_1a + seq_2b])\n",
    "        amplicon_list.append(['1a_3a', seq_1a + reverse_complement(seq_3a)])\n",
    "        amplicon_list.append(['1a_3b', seq_1a + seq_3b])\n",
    "\n",
    "        amplicon_list.append(['1b_1b', reverse_complement(seq_1b) + seq_1b])\n",
    "        amplicon_list.append(['2a_1b', seq_2a + seq_1b])\n",
    "        amplicon_list.append(['2b_1b', reverse_complement(seq_2b) + seq_1b])\n",
    "        amplicon_list.append(['3a_1b', seq_3a + seq_1b])\n",
    "        amplicon_list.append(['3b_1b', reverse_complement(seq_3b) + seq_1b])\n",
    "\n",
    "        amplicon_list.append(['2a_2a', seq_2a + reverse_complement(seq_2a)])\n",
    "        amplicon_list.append(['2a_2b', seq_2a + seq_2b])\n",
    "        amplicon_list.append(['2a_3a', seq_2a + reverse_complement(seq_3a)])\n",
    "        amplicon_list.append(['2a_3b', seq_2a + seq_3b])\n",
    "\n",
    "        amplicon_list.append(['2b_2b', reverse_complement(seq_2b) + seq_2b])\n",
    "        amplicon_list.append(['3a_2b', seq_3a + seq_2b])\n",
    "        amplicon_list.append(['3b_2b', reverse_complement(seq_3b) + seq_2b])\n",
    "\n",
    "        amplicon_list.append(['3a_3a', seq_3a + reverse_complement(seq_3a)])\n",
    "        amplicon_list.append(['3a_3b', seq_3a + seq_3b])\n",
    "\n",
    "        amplicon_list.append(['3b_3b', reverse_complement(seq_3b) + seq_3b])\n",
    "        \n",
    "    write_amplicon(dir_sample, amplicon_info, amplicon_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the amplicons by calling the create_amplicon function\n",
    "assembly = amplicon_info['genome']\n",
    "file_genome_2bit = os.path.join('/media/edanner/NewUbuntuSpace/Workspace/Ref_Genomes', assembly + '.2bit')\n",
    "\n",
    "create_amplicon(directory, amplicon_info, file_genome_2bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_plasmid_local(dir_sample, amplicon_info, ncpu=4):\n",
    "\n",
    "    # We first check if the experiment had any guides\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "    # exp_dir = create_filename(dir_sample, N7, N5, 'mainfolder')\n",
    "\n",
    "    file_cutadapt_R1 = create_filename(dir_sample, N7, N5, 'R1trimmed')\n",
    "    file_cutadapt_R2 = create_filename(dir_sample, N7, N5, 'R2trimmed')\n",
    "\n",
    "    file_sam_plasmid_local = create_filename(dir_sample, N7, N5, 'sam_plasmid_local')\n",
    "    file_sam_report_plasmid_local = create_filename(dir_sample, N7, N5, 'sam_report_plasmid_local')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_sam_plasmid_local)):\n",
    "        os.mkdir(os.path.dirname(file_sam_plasmid_local))\n",
    "\n",
    "    file_bam_plasmid_local = create_filename(dir_sample, N7, N5, 'bam_plasmid_local')\n",
    "    file_sorted_bam_plasmid_local = create_filename(dir_sample, N7, N5, 'sorted_bam_plasmid_local')\n",
    "    # file_sorted_bai_genome_local = create_filename(dir_sample, N7, N5, 'sorted_bai_genome_local')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_bam_plasmid_local)):\n",
    "        os.mkdir(os.path.dirname(file_bam_plasmid_local))\n",
    "\n",
    "    # local alignment to the genome with bowtie2\n",
    "    initial_dir = os.getcwd()\n",
    "\n",
    "    folder_amplicons = create_filename(dir_sample, N7, N5, 'amplicons')\n",
    "\n",
    "    os.chdir(folder_amplicons)\n",
    "\n",
    "    bowtie2_command = ['bowtie2', '--local', '-p', str(ncpu),\n",
    "                       '-X', '5000', '-k', '2', '-x', 'plasmid',\n",
    "                             '-1', file_cutadapt_R1, '-2', file_cutadapt_R2,\n",
    "                             '-S', file_sam_plasmid_local]\n",
    "\n",
    "    handle_sam_report_genome_local = open(file_sam_report_plasmid_local, 'wb')\n",
    "\n",
    "    subprocess.call(bowtie2_command, stderr=handle_sam_report_genome_local)\n",
    "\n",
    "    handle_sam_report_genome_local.close()\n",
    "\n",
    "    # convert sam to bam\n",
    "    sam_to_bam_plasmid_local_command = ['samtools', 'view', '-Sb', file_sam_plasmid_local]\n",
    "\n",
    "    handle_file_bam_plasmid_local = open(file_bam_plasmid_local, 'wb')\n",
    "\n",
    "    subprocess.call(sam_to_bam_plasmid_local_command, stdout=handle_file_bam_plasmid_local)\n",
    "\n",
    "    # sort bam files\n",
    "    sort_bam_plasmid_local_command = ['samtools', 'sort', file_bam_plasmid_local, '-o', file_sorted_bam_plasmid_local]\n",
    "\n",
    "    subprocess.call(sort_bam_plasmid_local_command)\n",
    "\n",
    "    # Create bam index files\n",
    "    create_bam_plasmid_local_index_command = ['samtools', 'index', file_sorted_bam_plasmid_local]\n",
    "    subprocess.call(create_bam_plasmid_local_index_command)\n",
    "\n",
    "    # Clean up\n",
    "    os.remove(file_sam_plasmid_local)\n",
    "    os.remove(file_bam_plasmid_local)\n",
    "\n",
    "    os.chdir(initial_dir)\n",
    "\n",
    "def extract_unmapped_reads_plasmid(dir_sample, amplicon_info):\n",
    "\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "\n",
    "    file_sorted_bam_plasmid_local = create_filename(dir_sample, N7, N5, 'sorted_bam_plasmid_local')\n",
    "\n",
    "    file_unmapped_bam_plasmid = create_filename(dir_sample, N7, N5, 'unmapped_bam_plasmid_local')\n",
    "\n",
    "    file_qsorted_unmapped_bam_plasmid = create_filename(dir_sample, N7, N5, 'qsorted_unmapped_bam_plasmid_local')\n",
    "\n",
    "    file_R1_unmapped = create_filename(dir_sample, N7, N5, 'unmapped_plasmid_R1fastq')\n",
    "    file_R2_unmapped = create_filename(dir_sample, N7, N5, 'unmapped_plasmid_R2fastq')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_R1_unmapped)):\n",
    "        os.mkdir(os.path.dirname(file_R1_unmapped))\n",
    "\n",
    "    extract_unmapped_bam_command = ['samtools', 'view', '-b', '-f', '0x4', file_sorted_bam_plasmid_local, '-o',\n",
    "                                    file_unmapped_bam_plasmid]\n",
    "\n",
    "    subprocess.call(extract_unmapped_bam_command)\n",
    "\n",
    "    qsort_unmapped_bam_command = ['samtools', 'sort', '-n', file_unmapped_bam_plasmid, '-o',\n",
    "                                  file_qsorted_unmapped_bam_plasmid]\n",
    "\n",
    "    subprocess.call(qsort_unmapped_bam_command)\n",
    "\n",
    "    bamtofastq_command = ['bedtools', 'bamtofastq', '-i', file_qsorted_unmapped_bam_plasmid,\n",
    "                          '-fq', file_R1_unmapped, '-fq2', file_R2_unmapped]\n",
    "\n",
    "    file_err = file_R1_unmapped[:-9] + '_err.txt'\n",
    "    handle_file_err = open(file_err, 'wb')\n",
    "\n",
    "    subprocess.call(bamtofastq_command, stderr=handle_file_err)\n",
    "\n",
    "    for fo in [file_R1_unmapped, file_R2_unmapped]:\n",
    "        with open(fo) as f_in, gzip.open(fo + '.gz', 'wb') as f_out:\n",
    "            f_out.writelines(f_in)\n",
    "        os.remove(fo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try out the alignment to the plasmid\n",
    "align_plasmid_local(directory, amplicon_info, ncpu=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the unmapped reads\n",
    "extract_unmapped_reads_plasmid(directory, amplicon_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze plasmid alignments\n",
    "\n",
    "def analyze_alignments_plasmid(dir_sample, amplicon_info, min_MAPQ, file_genome_2bit, do_plasmid):\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "        \n",
    "    exp_dir = create_filename(dir_sample, N7, N5, 'mainfolder')\n",
    "\n",
    "    file_UMI = create_filename(dir_sample, N7, N5, 'umifastqgz')\n",
    "    UMI_dict = create_barcode_dict(file_UMI)\n",
    "    \n",
    "    results_folder = os.path.join(exp_dir, 'results')\n",
    "    if not os.path.exists(results_folder):\n",
    "        os.mkdir(results_folder)\n",
    "\n",
    "    results_file = create_filename(dir_sample, N7, N5, 'results_plasmid')\n",
    "\n",
    "    if do_plasmid:\n",
    "        file_sorted_bam_plasmid_local = create_filename(dir_sample, N7, N5, 'sorted_bam_plasmid_local')\n",
    "\n",
    "        bam_in_alignment_file = pysam.AlignmentFile(file_sorted_bam_plasmid_local, 'rb')\n",
    "        bam_in = bam_in_alignment_file.fetch()\n",
    "\n",
    "        genome = twobitreader.TwoBitFile(file_genome_2bit)  # Load genome. Used for getting the sequences\n",
    "        \n",
    "        length_to_test = 15  # We check this number of bases after the primer\n",
    "        uditas_primer_length = int(amplicon_info['end'] - amplicon_info['start'])\n",
    "        \n",
    "        if amplicon_info['strand'] == '+':  # This is the UDiTaS oligo strand\n",
    "            #I had to add int() command to make this work for some reason\n",
    "            seq_after_uditas_primer = genome[amplicon_info['chr']][int(amplicon_info['end']):int((amplicon_info['end'] + length_to_test))]\n",
    "            \n",
    "        elif amplicon_info['strand'] == '-':\n",
    "            \n",
    "            seq_after_uditas_primer = reverse_complement(genome[amplicon_info['chr']][(int(amplicon_info['start']) - length_to_test):int(amplicon_info['start'])])\n",
    "\n",
    "        n_max_mismatches = 2  # We allow this number of mismatches between the read and the sequence after the primer\n",
    "\n",
    "        names_list_plasmid_genome = []\n",
    "        UMI_list_plasmid_genome = []\n",
    "        names_list_plasmid_only = []\n",
    "        UMI_list_plasmid_only = []\n",
    "        \n",
    "        for read in bam_in:\n",
    "            if read.mapping_quality >= min_MAPQ and not read.is_unmapped and not read.is_secondary:\n",
    "                if read.is_read2:  # R2 is the UDiTaS primer\n",
    "                    if read.is_reverse:\n",
    "                        seq_test = reverse_complement(read.query_sequence)[int(uditas_primer_length):int(uditas_primer_length + length_to_test)]\n",
    "                    else:                \n",
    "                        seq_test = read.query_sequence[int(uditas_primer_length):int(uditas_primer_length + length_to_test)]\n",
    "                        \n",
    "                    # Sometimes, after cutadapt we have a read shorter than uditas_primer_length + length_to_test\n",
    "                    # We skip those directly without calculating hamm_dist, which doesn't make sense\n",
    "                    if (len(seq_test) == len(seq_after_uditas_primer.upper()) and\n",
    "                        hamm_dist(seq_test, seq_after_uditas_primer.upper()) <= n_max_mismatches):\n",
    "                        # Reads for which the R2 has genomic sequence after the UDiTaS primer\n",
    "                        UMI_list_plasmid_genome.append(UMI_dict[read.query_name][0])\n",
    "                        names_list_plasmid_genome.append(read.query_name)\n",
    "                    else: # We put those short reads into the plasmid only bucket\n",
    "                        UMI_list_plasmid_only.append(UMI_dict[read.query_name][0])\n",
    "                        names_list_plasmid_only.append(read.query_name)\n",
    "        total_reads_plasmid_genome = len(set(names_list_plasmid_genome))\n",
    "        total_reads_collapsed_plasmid_genome = len(set(UMI_list_plasmid_genome))\n",
    "        total_reads_plasmid_only = len(set(names_list_plasmid_only))\n",
    "        total_reads_collapsed_plasmid_only = len(set(UMI_list_plasmid_only))\n",
    "\n",
    "        results_df = pd.DataFrame({'target_plus_plasmid_total_reads': [total_reads_plasmid_genome],\n",
    "                                   'target_plus_plasmid_total_reads_collapsed': [total_reads_collapsed_plasmid_genome],\n",
    "                                   'plasmid_only_total_reads': [total_reads_plasmid_only],\n",
    "                                   'plasmid_only_total_reads_collapsed': [total_reads_collapsed_plasmid_only]\n",
    "                                   },\n",
    "                                  columns=['target_plus_plasmid_total_reads',\n",
    "                                           'target_plus_plasmid_total_reads_collapsed',\n",
    "                                           'plasmid_only_total_reads',\n",
    "                                           'plasmid_only_total_reads_collapsed'])\n",
    "    else:\n",
    "        results_df = pd.DataFrame(index=np.arange(1),\n",
    "                                  columns=['target_plus_plasmid_total_reads',\n",
    "                                           'target_plus_plasmid_total_reads_collapsed',\n",
    "                                           'plasmid_only_total_reads',\n",
    "                                           'plasmid_only_total_reads_collapsed'])\n",
    "\n",
    "    results_df.to_excel(results_file)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "#################################################################################\n",
    "# Function to create barcode dict\n",
    "#################################################################################\n",
    "def create_barcode_dict(filename):\n",
    "    barcode_file = open_fastq_or_gz(filename)\n",
    "\n",
    "    barcode_dict = dict()\n",
    "\n",
    "    barcode_reads = itertools.izip(barcode_file)\n",
    "\n",
    "    for header_barcode in barcode_reads:\n",
    "        seq_barcode = barcode_reads.next()\n",
    "        barcode_reads.next()\n",
    "        qual_barcode = barcode_reads.next()\n",
    "        barcode_dict[header_barcode[0].split()[0][1:]] = [seq_barcode[0].rstrip(), qual_barcode[0].rstrip()]\n",
    "\n",
    "    return barcode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_plus_plasmid_total_reads</th>\n",
       "      <th>target_plus_plasmid_total_reads_collapsed</th>\n",
       "      <th>plasmid_only_total_reads</th>\n",
       "      <th>plasmid_only_total_reads_collapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6758</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_plus_plasmid_total_reads  target_plus_plasmid_total_reads_collapsed  \\\n",
       "0                                0                                          0   \n",
       "\n",
       "   plasmid_only_total_reads  plasmid_only_total_reads_collapsed  \n",
       "0                      6758                                  88  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run the plasmid analysis to coudn plasmid integration events\n",
    "result_plasmid_df = analyze_alignments_plasmid(directory, amplicon_info, min_MAPQ, file_genome_2bit, True)\n",
    "result_plasmid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#\n",
    "# Aligns reads globally to amplicon. \"end-to-end\" as the default function in bowtie2\n",
    "# Input: directory to be analyzed\n",
    "#        amplicon_info, slice of sample_info.csv for the sample being processed\n",
    "#        file_genome_2bit, 2bit file with the reference genome being used\n",
    "#\n",
    "# ##########################\n",
    "def align_amplicon(dir_sample, amplicon_info, check_plasmid_insertions, ncpu=4):\n",
    "\n",
    "    # We first check if the experiment had any guides\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "\n",
    "    has_plasmid = type(amplicon_info['plasmid_sequence']) is str or type(amplicon_info['plasmid_sequence']) is unicode\n",
    "\n",
    "    if check_plasmid_insertions == 1 and has_plasmid:\n",
    "        file_R1 = create_filename(dir_sample, N7, N5, 'unmapped_plasmid_R1fastqgz')\n",
    "        file_R2 = create_filename(dir_sample, N7, N5, 'unmapped_plasmid_R2fastqgz')\n",
    "    else:\n",
    "        file_R1 = create_filename(dir_sample, N7, N5, 'R1trimmed')\n",
    "        file_R2 = create_filename(dir_sample, N7, N5, 'R2trimmed')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_R1)):\n",
    "        os.mkdir(os.path.dirname(file_R1))\n",
    "\n",
    "    file_sam_amplicons = create_filename(dir_sample, N7, N5, 'sam_amplicons')\n",
    "    file_sam_report_amplicons = create_filename(dir_sample, N7, N5, 'sam_report_amplicons')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_sam_amplicons)):\n",
    "        os.mkdir(os.path.dirname(file_sam_amplicons))\n",
    "\n",
    "    file_bam_amplicons = create_filename(dir_sample, N7, N5, 'bam_amplicons')\n",
    "    file_sorted_bam_amplicons = create_filename(dir_sample, N7, N5, 'sorted_bam_amplicons')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_bam_amplicons)):\n",
    "        os.mkdir(os.path.dirname(file_bam_amplicons))\n",
    "\n",
    "    # global alignment to the amplicons with bowtie2\n",
    "    initial_dir = os.getcwd()\n",
    "    folder_amplicons = create_filename(dir_sample, N7, N5, 'amplicons')\n",
    "\n",
    "    os.chdir(folder_amplicons)\n",
    "    bowtie2_command = ['bowtie2', '-p', str(ncpu), '--very-sensitive',\n",
    "                       '-X', '5000', '-k', '2', '-x', 'amplicons',\n",
    "                       '-1', file_R1, '-2', file_R2,\n",
    "                       '-S', file_sam_amplicons]\n",
    "\n",
    "    handle_sam_report_amplicons = open(file_sam_report_amplicons, 'wb')\n",
    "\n",
    "    subprocess.call(bowtie2_command, stderr=handle_sam_report_amplicons)\n",
    "\n",
    "    handle_sam_report_amplicons.close()\n",
    "\n",
    "    # convert sam to bam\n",
    "    sam_to_bam_amplicons_command = ['samtools', 'view', '-Sb', file_sam_amplicons]\n",
    "\n",
    "    handle_file_bam_amplicons = open(file_bam_amplicons, 'wb')\n",
    "\n",
    "    subprocess.call(sam_to_bam_amplicons_command, stdout=handle_file_bam_amplicons)\n",
    "\n",
    "    # sort bam files\n",
    "    sort_bam_amplicons_command = ['samtools', 'sort', file_bam_amplicons, '-o', file_sorted_bam_amplicons]\n",
    "\n",
    "    subprocess.call(sort_bam_amplicons_command)\n",
    "\n",
    "    # Clean up\n",
    "    os.remove(file_sam_amplicons)\n",
    "    os.remove(file_bam_amplicons)\n",
    "\n",
    "    # Create bam index files\n",
    "    create_bam_amplicons_index_command = ['samtools', 'index', file_sorted_bam_amplicons]\n",
    "    subprocess.call(create_bam_amplicons_index_command)\n",
    "\n",
    "    os.chdir(initial_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Function to extract all unmapped reads to the amplicons\n",
    "################################################################################\n",
    "def extract_unmapped_reads_amplicons(dir_sample, amplicon_info):\n",
    "\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "\n",
    "    file_sorted_bam_amplicons = create_filename(dir_sample, N7, N5, 'sorted_bam_amplicons')\n",
    "\n",
    "    file_unmapped_bam_amplicons = create_filename(dir_sample, N7, N5, 'unmapped_bam_amplicons')\n",
    "\n",
    "    file_qsorted_unmapped_bam_amplicons = create_filename(dir_sample, N7, N5, 'qsorted_unmapped_bam_amplicons')\n",
    "\n",
    "    file_R1_unmapped = create_filename(dir_sample, N7, N5, 'unmapped_amplicons_R1fastq')\n",
    "    file_R2_unmapped = create_filename(dir_sample, N7, N5, 'unmapped_amplicons_R2fastq')\n",
    "    file_unmapped_report = create_filename(dir_sample, N7, N5, 'unmapped_amplicons_report')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_R1_unmapped)):\n",
    "        os.mkdir(os.path.dirname(file_R1_unmapped))\n",
    "\n",
    "    extract_unmapped_bam_command = ['samtools', 'view', '-b', '-f', '0x4', file_sorted_bam_amplicons, '-o',\n",
    "                                    file_unmapped_bam_amplicons]\n",
    "\n",
    "    subprocess.call(extract_unmapped_bam_command)\n",
    "\n",
    "    qsort_unmapped_bam_command = ['samtools', 'sort', '-n', file_unmapped_bam_amplicons, '-o',\n",
    "                                  file_qsorted_unmapped_bam_amplicons]\n",
    "\n",
    "    subprocess.call(qsort_unmapped_bam_command)\n",
    "\n",
    "    bamtofastq_command = ['bedtools', 'bamtofastq', '-i', file_qsorted_unmapped_bam_amplicons,\n",
    "                          '-fq', file_R1_unmapped, '-fq2', file_R2_unmapped]\n",
    "\n",
    "    handle_unmapped_report = open(file_unmapped_report, 'wb')\n",
    "    subprocess.call(bamtofastq_command, stderr=handle_unmapped_report)\n",
    "\n",
    "    for fo in [file_R1_unmapped, file_R2_unmapped]:\n",
    "        with open(fo) as f_in, gzip.open(fo + '.gz', 'wb') as f_out:\n",
    "            f_out.writelines(f_in)\n",
    "        os.remove(fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#align against our suite of amplicons\n",
    "align_amplicon(directory, amplicon_info, check_plasmid_insertions, ncpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will extract unmap reads new folder (files that did not align to the predicted structural variants)\n",
    "extract_unmapped_reads_amplicons(directory, amplicon_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This section is to do the analysis of the amplicon alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Function to calculate the number of reads and collapsed reads aligned to the reference amplicons\n",
    "# litterally just gives 2 numbers. Number of amplicons that were aligned and the number after collapse. Doesn't break it down by alignment to any particular amplicon\n",
    "################################################################################\n",
    "def analyze_alignments_all_amplicons(dir_sample, amplicon_info, min_MAPQ, min_AS):\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "\n",
    "    exp_dir = create_filename(dir_sample, N7, N5, 'mainfolder')\n",
    "\n",
    "    file_UMI = create_filename(dir_sample, N7, N5, 'umifastqgz')\n",
    "    UMI_dict = create_barcode_dict(file_UMI)\n",
    "    \n",
    "    ## THIS was added to get an idea of how many unique reads there are.\n",
    "    a=list(UMI_dict.values())\n",
    "    lst2 = [item[0] for item in a]\n",
    "    print('number of reads before mispriming cleanup',len(lst2))\n",
    "    print('number of unique umis before mispriming cleanup',len(set(lst2)))\n",
    "    \n",
    "    results_folder = os.path.join(exp_dir, 'results')\n",
    "    if not os.path.exists(results_folder):\n",
    "        os.mkdir(results_folder)\n",
    "\n",
    "    results_file = create_filename(dir_sample, N7, N5, 'results_all_amplicons')\n",
    "\n",
    "    file_sorted_bam_amplicons = create_filename(dir_sample, N7, N5, 'sorted_bam_amplicons')\n",
    "\n",
    "    bam_in_alignment_file = pysam.AlignmentFile(file_sorted_bam_amplicons, 'rb')\n",
    "\n",
    "    bam_in_all = bam_in_alignment_file.fetch()\n",
    "\n",
    "    names_list_amplicons = []\n",
    "    UMI_list_amplicons = []\n",
    "\n",
    "    for read in bam_in_all:\n",
    "        if read.has_tag('AS'):\n",
    "            read_AS = read.get_tag('AS')\n",
    "        # We test first if the read is unmapped, otherwise read_AS would be undefined\n",
    "        if not read.is_unmapped and read.mapping_quality >= min_MAPQ \\\n",
    "                and read_AS >= min_AS and not read.is_secondary:\n",
    "            UMI_list_amplicons.append(UMI_dict[read.query_name][0])\n",
    "            names_list_amplicons.append(read.query_name)\n",
    "\n",
    "    all_amplicons_total_reads = len(set(names_list_amplicons))\n",
    "    all_amplicons_total_reads_collapsed = len(set(UMI_list_amplicons))\n",
    "\n",
    "    results_df = pd.DataFrame({'all_amplicons_total_reads': [all_amplicons_total_reads],\n",
    "                               'all_amplicons_total_reads_collapsed': [all_amplicons_total_reads_collapsed]\n",
    "                               },\n",
    "                              columns=['all_amplicons_total_reads',\n",
    "                                       'all_amplicons_total_reads_collapsed'])\n",
    "\n",
    "    results_df.to_excel(results_file)\n",
    "\n",
    "    return results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reads before mispriming cleanup 407906\n",
      "number of unique umis before mispriming cleanup 174757\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_amplicons_total_reads</th>\n",
       "      <th>all_amplicons_total_reads_collapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86945</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   all_amplicons_total_reads  all_amplicons_total_reads_collapsed\n",
       "0                      86945                                 1888"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_reads_in_all_amplicons_df = analyze_alignments_all_amplicons(directory, amplicon_info, min_MAPQ, min_AS)\n",
    "result_reads_in_all_amplicons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from Uditas to analyze the alignments. These support analyze_alignment()\n",
    "# This analysis looks at the indel distribution at the different cut sites.\n",
    "\n",
    "# the follwoing 2 functions- parse_indels() and get_intersection() are used in the 3rd function find_indels().\n",
    "# parse_indels(), get_intersection(), find_indels() are unchanged from uditas\n",
    "\n",
    "\n",
    "# find_indels() will be used in analyze_alignments() (along with other functions)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# parse_indels\n",
    "#\n",
    "# Author: David Kelly\n",
    "#\n",
    "# Parse the CIGAR tuples for the positions and lengths of insertions and\n",
    "# deletions implied by the aligned read.\n",
    "#\n",
    "# Input\n",
    "#  aligned_read:  pysam AlignedSegment object\n",
    "#\n",
    "# Output\n",
    "#  indels:        list of (position, indel_length) tuples. indel_lengths are\n",
    "#                  positive for insertions, negative for deletions.\n",
    "################################################################################\n",
    "def parse_indels(aligned_read):\n",
    "    indels = []\n",
    "\n",
    "    if not aligned_read.is_unmapped and not aligned_read.is_secondary:  # We only look at primary alignments\n",
    "        ref_i = aligned_read.reference_start\n",
    "        for operation, length in aligned_read.cigartuples:\n",
    "            if operation == 0:\n",
    "                ref_i += length\n",
    "            elif operation == 1:\n",
    "                indels.append((ref_i, length))\n",
    "            elif operation == 2:\n",
    "                indels.append((ref_i, -length))\n",
    "                ref_i += length\n",
    "            else:\n",
    "                print >> sys.stderr, 'Unrecognized CIGAR operation for %s' % aligned_read.query_name\n",
    "\n",
    "    return indels\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Function to get the number of intersecting bases between two intervals\n",
    "################################################################################\n",
    "def get_intersection(region1_begin, region1_end, region2_begin, region2_end):\n",
    "    list1 = range(int(region1_begin) + 1, int(region1_end) + 1)\n",
    "    list2 = range(int(region2_begin) + 1, int(region2_end) + 1)\n",
    "    return len(set(list1).intersection(list2))\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# find_indels\n",
    "#\n",
    "# Input\n",
    "#  bam_file:               alignments file to process\n",
    "#\n",
    "################################################################################\n",
    "def find_indels(bam_file, strand, region_chr, region_start, region_end, UMI_dict, min_MAPQ, min_AS):\n",
    "    bam_in_alignment_file = pysam.AlignmentFile(bam_file, 'rb')\n",
    "\n",
    "    # We get the reads that overlap the window in which we make the counts\n",
    "    # fetch will get reads with any overlap with the window\n",
    "    # For UDiTaS, care must be take to ensure that the read covers the whole window, some short reads may cover just\n",
    "    # one side of the window, depending on the direction of the UDiTaS primer\n",
    "    bam_in = bam_in_alignment_file.fetch(region_chr, region_start, region_end)\n",
    "\n",
    "    names_list = []\n",
    "    position_list = []\n",
    "    indel_list = []\n",
    "    UMI_list = []\n",
    "    for read in bam_in:\n",
    "        # We add here a check to make sure the read came from the primer, crossed the cut and covered the whole window\n",
    "        if read.has_tag('AS'):\n",
    "            read_AS = read.get_tag('AS')\n",
    "        # We test first if the read is unmapped, otherwise read_AS would be undefined\n",
    "        if not read.is_unmapped and (((read.reference_start < region_start) and\n",
    "                 (read.reference_end > region_end)) and\n",
    "                    read.mapping_quality >= min_MAPQ and\n",
    "                    read_AS >= min_AS and  not read.is_secondary):\n",
    "            read_indels = parse_indels(read)\n",
    "            # if no indels found, write 0\n",
    "            if len(read_indels) == 0:\n",
    "                read_indels.append(('-', 0))\n",
    "\n",
    "            # print indels to table\n",
    "            for pos, indel in read_indels:\n",
    "                names_list.append(read.query_name)\n",
    "                if pos == '-':\n",
    "                    position_list.append(-1)\n",
    "                else:\n",
    "                    position_list.append(int(pos))\n",
    "\n",
    "                indel_list.append(indel)\n",
    "                UMI_list.append(UMI_dict[read.query_name][0])\n",
    "\n",
    "    df = pd.DataFrame({'read_name': names_list,\n",
    "                       'position': position_list,\n",
    "                       'indel': indel_list,\n",
    "                       'UMI': UMI_list})\n",
    "\n",
    "    df['position_end'] = df.position + np.abs(df.indel)\n",
    "\n",
    "    overlap = [get_intersection(df.loc[index]['position'], df.loc[index]['position_end'], region_start, region_end)\n",
    "               for index in range(df.shape[0])]\n",
    "\n",
    "    position_filter = np.array(overlap) > 0\n",
    "\n",
    "    deletion_filter = position_filter & np.array(df.indel < 0)\n",
    "\n",
    "    insertion_filter = position_filter & np.array(df.indel > 0)\n",
    "\n",
    "    total_reads_in_region = len(set(df['read_name']))\n",
    "    total_collapsed_reads_in_region = len(set(df['UMI']))\n",
    "\n",
    "    total_indels = len(set(df.loc[position_filter]['read_name']))\n",
    "    total_collapsed_indels = len(set(df.loc[position_filter]['UMI']))\n",
    "\n",
    "    total_deletions = len(set(df.loc[deletion_filter]['read_name']))\n",
    "    total_collapsed_deletions = len(set(df.loc[deletion_filter]['UMI']))\n",
    "\n",
    "    total_insertions = len(set(df.loc[insertion_filter]['read_name']))\n",
    "    total_collapsed_insertions = len(set(df.loc[insertion_filter]['UMI']))\n",
    "\n",
    "    return [total_reads_in_region, total_indels, total_deletions, total_insertions,\n",
    "            total_collapsed_reads_in_region,\n",
    "            total_collapsed_indels,\n",
    "            total_collapsed_deletions,\n",
    "            total_collapsed_insertions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from Uditas to analyze the alignments. These support analyze_alignment()\n",
    "\n",
    "# create_segments() is used in analyze_fragment_sizes(). Analyze_fragment_sizes is used in analyze_alignments()\n",
    "# These functions are unchanged from Uditas\n",
    "\n",
    "################################################################################\n",
    "# helper function to create list of fragment coordinates, useful to get size statistics\n",
    "################################################################################\n",
    "def create_segments(iter1, bam_in, min_MAPQ):\n",
    "    segments = list()\n",
    "    for read in iter1:\n",
    "        if read.mapping_quality >= min_MAPQ and read.is_read2 and read.is_paired:\n",
    "            if read.is_reverse:\n",
    "                segment_start = read.reference_end + read.tlen  # Note: read.tlen is < 0\n",
    "                segment_end = read.reference_end  # pysam is 0 based\n",
    "            else:\n",
    "                segment_start = read.reference_start  # pysam is 0 based\n",
    "                segment_end = read.reference_start + read.tlen\n",
    "\n",
    "            if segment_start < 0:  # We don't want to go below 0\n",
    "                segment_start = 0\n",
    "\n",
    "            if segment_end > segment_start:\n",
    "                segments.append((bam_in.getrname(read.reference_id), segment_start,\n",
    "                                 segment_end))\n",
    "\n",
    "    return segments\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Function to analyse fragment sizes\n",
    "################################################################################\n",
    "def analyze_fragment_sizes(dir_sample, amplicon_info, min_MAPQ):\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "    file_sorted_bam_amplicons = create_filename(dir_sample, N7, N5, 'sorted_bam_amplicons')\n",
    "\n",
    "    # Section to plot\n",
    "    file_figure_classes = (create_filename(dir_sample, N7, N5, 'results_amplicons') + '_fragment_sizes_classes.pdf')\n",
    "    file_figure = (create_filename(dir_sample, N7, N5, 'results_amplicons') + '_fragment_sizes.pdf')\n",
    "\n",
    "    bam_in = pysam.AlignmentFile(file_sorted_bam_amplicons, \"rb\")\n",
    "\n",
    "    iter_bam_in = bam_in.fetch()\n",
    "\n",
    "    segments_bam_in = create_segments(iter_bam_in, bam_in, min_MAPQ)\n",
    "\n",
    "    df = pd.DataFrame(segments_bam_in, columns=['type', 'begin', 'end'])\n",
    "    df['length'] = df['end'] - df['begin']\n",
    "\n",
    "    if df.shape[0] > 0:\n",
    "        median_size = np.median(df['length'])\n",
    "\n",
    "        file_fragments = (create_filename(dir_sample, N7, N5, 'results_amplicons') + '_fragment_sizes.xlsx')\n",
    "        df.to_excel(file_fragments, index=False)\n",
    "\n",
    "        df2 = df.pivot(columns='type', values='length')\n",
    "\n",
    "        up_limit = 700\n",
    "        fs = 20\n",
    "        plt.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "\n",
    "        # if df2.shape\n",
    "        # plot with categories separated by colors\n",
    "        df2.plot.hist(stacked=True, bins=np.arange(0, up_limit, 20))\n",
    "        plt.xlim(0, up_limit)\n",
    "        plt.xlabel('Fragment Size (bp)', fontsize=fs)\n",
    "        plt.ylabel('Counts', fontsize=fs)\n",
    "        plt.xticks(fontsize=fs)\n",
    "        plt.yticks(fontsize=fs)\n",
    "        if len(plt.gca().get_legend_handles_labels()[0]) > 0:  # To prevent warning from legend\n",
    "            plt.legend(fontsize=12)\n",
    "        pylab.savefig(file_figure_classes, bbox_inches='tight')\n",
    "        plt.close(plt.gcf())\n",
    "\n",
    "        # plot with all categories with the same color\n",
    "        plt.hist(df['length'], np.arange(0, up_limit, 20))\n",
    "        plt.xlim(0, up_limit)\n",
    "        plt.xlabel('Fragment Size (bp)', fontsize=fs)\n",
    "        plt.ylabel('Counts', fontsize=fs)\n",
    "        plt.xticks(fontsize=fs)\n",
    "        plt.yticks(fontsize=fs)\n",
    "        if len(plt.gca().get_legend_handles_labels()[0]) > 0:  # To prevent warning from legend\n",
    "            plt.legend(fontsize=12)\n",
    "        pylab.savefig(file_figure, bbox_inches='tight')\n",
    "        plt.close(plt.gcf())\n",
    "    else:\n",
    "        median_size = 0\n",
    "\n",
    "    bam_in.close()\n",
    "\n",
    "    return median_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from Uditas to analyze the alignments. These support analyze_alignment()\n",
    "\n",
    "# get_cut_in_reference_amplicon_df() is used in znalyze_alignment()\n",
    "# This had to be altered to get the cuts for REPLACE\n",
    "\n",
    "\n",
    "\n",
    "#######################################\n",
    "# Function to get cut list depending on amplicon type\n",
    "# Inputs are reaction_type and fasta record\n",
    "# This function is needed to catch the cases when there are zero (control) or two cuts in the reference amplicon,\n",
    "# eg when we have two cuts in the same chromosome\n",
    "#\n",
    "# The cut positions in the output depend on how the amplicons were constructed in create_amplicon. A change in\n",
    "# that function must be matched in this function\n",
    "#\n",
    "# output: list with pairs of prefixes and cut positions [['cut1', pos1], 'cut2', pos2]]\n",
    "#######################################\n",
    "def get_cut_in_reference_amplicon_df(amplicon_info, reaction_type, record, strand, window_size, amplicon_window_around_cut):\n",
    "    cut_in_reference_amplicon_df = pd.DataFrame(columns=['cut_type', 'cut_position'])\n",
    "    if reaction_type == 'control':\n",
    "        if strand == '+':\n",
    "            # For the control sample (just primer, no cuts) we will look at counts and indels as if there was a cut\n",
    "            # in position window_size\n",
    "            cut_in_reference_amplicon_df.loc[0] = ['', window_size + 1]\n",
    "        else:  # For the - strand we count reads at the end of the amplicon\n",
    "            cut_in_reference_amplicon_df.loc[0] = ['', amplicon_window_around_cut - window_size - 2]\n",
    "    elif reaction_type in ['single_cut', 'double_cut_different_chromosomes', 'triple_cut_different_chromosomes']:\n",
    "        # We need to get cut1 in case its coordinates are smaller than amplicon_window_around_cut\n",
    "        if amplicon_info['strand_guide_1'] == '+':\n",
    "            # sp or sa for the moment only\n",
    "            cut1 = amplicon_info['end_guide_1'] - 3\n",
    "        elif amplicon_info['strand_guide_1'] == '-':\n",
    "            cut1 = amplicon_info['start_guide_1'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_1 can only have as values + or -')\n",
    "\n",
    "        if cut1 < amplicon_window_around_cut:\n",
    "            cut_site = cut1\n",
    "        else:\n",
    "            cut_site = amplicon_window_around_cut\n",
    "\n",
    "        # all amplicons have a single cut at position amplicon_window_around_cut\n",
    "        cut_in_reference_amplicon_df.loc[0] = ['cut1', cut_site]\n",
    "    elif reaction_type == 'double_cut_same_chromosome':\n",
    "        # Case two guides on the same chromosome\n",
    "        if amplicon_info['strand_guide_1'] == '+':\n",
    "            # sp or sa for the moment only\n",
    "            cut1 = amplicon_info['end_guide_1'] - 3\n",
    "        elif amplicon_info['strand_guide_1'] == '-':\n",
    "            cut1 = amplicon_info['start_guide_1'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_1 can only have as values + or -')\n",
    "\n",
    "        if amplicon_info['strand_guide_2'] == '+':\n",
    "            cut2 = amplicon_info['end_guide_2'] - 3\n",
    "        elif amplicon_info['strand_guide_2'] == '-':\n",
    "            cut2 = amplicon_info['start_guide_2'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_2 can only have as values + or -')\n",
    "\n",
    "        # We switch the coordinates of cut1 and cut2 if the guides are provided so that cut2 < cut1\n",
    "        # cut1 it will always be smaller than cut2 and in the results cut1 will be the cut site with\n",
    "        # smaller genomic coordinate\n",
    "        # cut1 and cut2 also flipped in create_amplicon\n",
    "\n",
    "        if cut2 < cut1:\n",
    "            (cut1, cut2) = (cut2, cut1)\n",
    "        if cut1 < amplicon_window_around_cut:\n",
    "            cut_site = cut1\n",
    "        else:\n",
    "            cut_site = amplicon_window_around_cut\n",
    "\n",
    "        # In this case some amplicons (wt, large_inversion) have two cuts, the rest have one\n",
    "        if record.name in ['wt', 'large_inversion']:\n",
    "            cut1_cut2_length = cut2 - cut1\n",
    "            cut_in_reference_amplicon_df.loc[0] = ['cut1', cut_site]\n",
    "            cut_in_reference_amplicon_df.loc[1] = ['cut2', cut_site + cut1_cut2_length]\n",
    "        else:\n",
    "            cut_in_reference_amplicon_df.loc[0] = ['cut1', cut_site]\n",
    "    elif reaction_type == 'replace':\n",
    "        # Case for replace targeting\n",
    "        if amplicon_info['strand_guide_1'] == '+':\n",
    "            # sp or sa for the moment only\n",
    "            cut1 = amplicon_info['end_guide_1'] - 3\n",
    "        elif amplicon_info['strand_guide_1'] == '-':\n",
    "            cut1 = amplicon_info['start_guide_1'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_1 can only have as values + or -')\n",
    "\n",
    "        if amplicon_info['strand_guide_2'] == '+':\n",
    "            cut2 = amplicon_info['end_guide_2'] - 3\n",
    "        elif amplicon_info['strand_guide_2'] == '-':\n",
    "            cut2 = amplicon_info['start_guide_2'] + 3\n",
    "        else:\n",
    "            raise StrandError('strand_guide_2 can only have as values + or -')\n",
    "\n",
    "        # We switch the coordinates of cut1 and cut2 if the guides are provided so that cut2 < cut1\n",
    "        # cut1 it will always be smaller than cut2 and in the results cut1 will be the cut site with\n",
    "        # smaller genomic coordinate\n",
    "        # cut1 and cut2 also flipped in create_amplicon\n",
    "\n",
    "        if cut2 < cut1:\n",
    "            (cut1, cut2) = (cut2, cut1)\n",
    "        if cut1 < amplicon_window_around_cut:\n",
    "            cut_site = cut1\n",
    "        else:\n",
    "            cut_site = amplicon_window_around_cut\n",
    "        \n",
    "        replace_length = int(len(amplicon_info['Replace_Donor']))\n",
    "        \n",
    "        # In this case some amplicons (wt, large_inversion) have two cuts, the rest have one\n",
    "        if record.name in ['wt', 'large_inversion']:\n",
    "            cut1_cut2_length = cut2 - cut1\n",
    "            cut_in_reference_amplicon_df.loc[0] = ['cut1', cut_site]\n",
    "            cut_in_reference_amplicon_df.loc[1] = ['cut2', cut_site + cut1_cut2_length]            \n",
    "        elif record.name in ['replace_fwd', 'replace_rev']:\n",
    "            cut_in_reference_amplicon_df.loc[0] = ['cut1', cut_site]\n",
    "            cut_in_reference_amplicon_df.loc[1] = ['cut2', cut_site + replace_length]\n",
    "        elif record.name in ['doner_tail_tail', 'doner_head_tail', 'doner_head_head']:\n",
    "            cut_in_reference_amplicon_df.loc[0] = ['cut1', replace_length]\n",
    "        else:\n",
    "            cut_in_reference_amplicon_df.loc[0] = ['cut1', cut_site]\n",
    "    else:\n",
    "        raise ReactionTypeError('Reaction type not yet supported by current version of UDiTaS')\n",
    "\n",
    "    return cut_in_reference_amplicon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#  Function to analyze indels and structural rearrangements from aligned reads to amplicons\n",
    "################################################################################\n",
    "def analyze_alignments(dir_sample, amplicon_info, window_size, amplicon_window_around_cut, min_MAPQ, min_AS):\n",
    "\n",
    "    reaction_type = get_reaction_type(amplicon_info)\n",
    "\n",
    "    # UDiTaS primer strand\n",
    "    strand = amplicon_info['strand']\n",
    "\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "    exp_dir = create_filename(dir_sample, N7, N5, 'mainfolder')\n",
    "    results_folder = os.path.join(exp_dir, 'results')\n",
    "    if not os.path.exists(results_folder):\n",
    "        os.mkdir(results_folder)\n",
    "\n",
    "    results_file = (create_filename(dir_sample, N7, N5, 'results_amplicons') + '_results_amplicon_window_'\n",
    "                    + str(window_size) + '.xlsx')\n",
    "\n",
    "    file_sorted_bam_amplicons = create_filename(dir_sample, N7, N5, 'sorted_bam_amplicons')\n",
    "\n",
    "    file_UMI = create_filename(dir_sample, N7, N5, 'umifastqgz')\n",
    "\n",
    "    UMI_dict = create_barcode_dict(file_UMI)\n",
    "\n",
    "    filename_amplicons_fa = os.path.join(exp_dir, 'amplicons', 'amplicons.fa')\n",
    "\n",
    "    results_df = pd.DataFrame(index=[0])\n",
    "\n",
    "    # We get the reference amplicon list\n",
    "    with open(filename_amplicons_fa, \"rU\") as handle:\n",
    "        records = list(SeqIO.parse(handle, \"fasta\"))\n",
    "\n",
    "    for record in records:\n",
    "        cut_df = get_cut_in_reference_amplicon_df(amplicon_info, reaction_type, record, strand, window_size,\n",
    "                                                  amplicon_window_around_cut)\n",
    "\n",
    "        # We go over cut1 and cut2 and when using cut1 we check if we are in control sample\n",
    "        for i in cut_df.index:\n",
    "            cut = cut_df.loc[i, 'cut_type']\n",
    "            cut_position = cut_df.loc[i, 'cut_position']\n",
    "            region_chr = record.name\n",
    "\n",
    "            region_start = cut_position - window_size\n",
    "            region_end = cut_position + window_size + 1\n",
    "\n",
    "            results = find_indels(file_sorted_bam_amplicons, strand, region_chr, region_start, region_end, UMI_dict,\n",
    "                                  min_MAPQ, min_AS)\n",
    "            # This is to catch the control case, no cut there\n",
    "            if len(cut) > 0:\n",
    "                prefix = region_chr + '_' + cut\n",
    "            else:\n",
    "                prefix = region_chr\n",
    "\n",
    "            results_df[prefix + '_total_reads'] = [results[0]]\n",
    "            results_df[prefix + '_total_indels'] = [results[1]]\n",
    "            results_df[prefix + '_total_deletions'] = [results[2]]\n",
    "            results_df[prefix + '_total_insertions'] = [results[3]]\n",
    "            results_df[prefix + '_total_reads_collapsed'] = [results[4]]\n",
    "            results_df[prefix + '_total_indels_collapsed'] = [results[5]]\n",
    "            results_df[prefix + '_total_deletions_collapsed'] = [results[6]]\n",
    "            results_df[prefix + '_total_insertions_collapsed'] = [results[7]]\n",
    "\n",
    "    median_size = analyze_fragment_sizes(dir_sample, amplicon_info, min_MAPQ)\n",
    "    results_df['median_fragment_size'] = [median_size]\n",
    "\n",
    "    results_df.to_excel(results_file)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wt_cut1_total_reads</th>\n",
       "      <th>wt_cut1_total_indels</th>\n",
       "      <th>wt_cut1_total_deletions</th>\n",
       "      <th>wt_cut1_total_insertions</th>\n",
       "      <th>wt_cut1_total_reads_collapsed</th>\n",
       "      <th>wt_cut1_total_indels_collapsed</th>\n",
       "      <th>wt_cut1_total_deletions_collapsed</th>\n",
       "      <th>wt_cut1_total_insertions_collapsed</th>\n",
       "      <th>wt_cut2_total_reads</th>\n",
       "      <th>wt_cut2_total_indels</th>\n",
       "      <th>...</th>\n",
       "      <th>1a_1a_cut1_total_insertions_collapsed</th>\n",
       "      <th>2b_2b_cut1_total_reads</th>\n",
       "      <th>2b_2b_cut1_total_indels</th>\n",
       "      <th>2b_2b_cut1_total_deletions</th>\n",
       "      <th>2b_2b_cut1_total_insertions</th>\n",
       "      <th>2b_2b_cut1_total_reads_collapsed</th>\n",
       "      <th>2b_2b_cut1_total_indels_collapsed</th>\n",
       "      <th>2b_2b_cut1_total_deletions_collapsed</th>\n",
       "      <th>2b_2b_cut1_total_insertions_collapsed</th>\n",
       "      <th>median_fragment_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11121</td>\n",
       "      <td>6323</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wt_cut1_total_reads  wt_cut1_total_indels  wt_cut1_total_deletions  \\\n",
       "0                    0                     0                        0   \n",
       "\n",
       "   wt_cut1_total_insertions  wt_cut1_total_reads_collapsed  \\\n",
       "0                         0                              0   \n",
       "\n",
       "   wt_cut1_total_indels_collapsed  wt_cut1_total_deletions_collapsed  \\\n",
       "0                               0                                  0   \n",
       "\n",
       "   wt_cut1_total_insertions_collapsed  wt_cut2_total_reads  \\\n",
       "0                                   0                11121   \n",
       "\n",
       "   wt_cut2_total_indels  ...  1a_1a_cut1_total_insertions_collapsed  \\\n",
       "0                  6323  ...                                      0   \n",
       "\n",
       "   2b_2b_cut1_total_reads  2b_2b_cut1_total_indels  \\\n",
       "0                       0                        0   \n",
       "\n",
       "   2b_2b_cut1_total_deletions  2b_2b_cut1_total_insertions  \\\n",
       "0                           0                            0   \n",
       "\n",
       "   2b_2b_cut1_total_reads_collapsed  2b_2b_cut1_total_indels_collapsed  \\\n",
       "0                                 0                                  0   \n",
       "\n",
       "   2b_2b_cut1_total_deletions_collapsed  \\\n",
       "0                                     0   \n",
       "\n",
       "   2b_2b_cut1_total_insertions_collapsed  median_fragment_size  \n",
       "0                                      0                 180.0  \n",
       "\n",
       "[1 rows x 113 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_amplicon_df = analyze_alignments(directory, amplicon_info, window_size, amplicon_window_around_cut, min_MAPQ, min_AS)\n",
    "result_amplicon_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the Global alignment of the remaining reads\n",
    "\n",
    "#### What I need here is to modify it so that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#\n",
    "# Aligns reads to the whole genome using bowtie2 and global alignment. This is used to find mispriming events\n",
    "#  and unmapped reads\n",
    "#\n",
    "# Input: directory to be analyzed\n",
    "#        amplicon_info, slice of sample_info.csv for the sample being processed\n",
    "#        assembly, name of the assembly to be used by bowtie2. It is convenient to place it in a folder especified by\n",
    "#        the environmental variable BOWTIE2_INDEXES\n",
    "#\n",
    "# ##########################\n",
    "def align_genome_global(dir_sample, amplicon_info, assembly, ncpu=4):\n",
    "\n",
    "    # We first check if the experiment had any guides\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "\n",
    "    file_R1 = create_filename(dir_sample, N7, N5, 'unmapped_amplicons_R1fastqgz')\n",
    "    file_R2 = create_filename(dir_sample, N7, N5, 'unmapped_amplicons_R2fastqgz')\n",
    "\n",
    "    file_sam_genome_global = create_filename(dir_sample, N7, N5, 'sam_genome_global')\n",
    "    file_sam_report_genome_global = create_filename(dir_sample, N7, N5, 'sam_report_genome_global')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_sam_genome_global)):\n",
    "        os.mkdir(os.path.dirname(file_sam_genome_global))\n",
    "\n",
    "    file_bam_genome_global = create_filename(dir_sample, N7, N5, 'bam_genome_global')\n",
    "    file_sorted_bam_genome_global = create_filename(dir_sample, N7, N5, 'sorted_bam_genome_global')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_bam_genome_global)):\n",
    "        os.mkdir(os.path.dirname(file_bam_genome_global))\n",
    "\n",
    "    # global alignment to the genome with bowtie2\n",
    "    initial_dir = os.getcwd()\n",
    "\n",
    "    bowtie2_command = ['bowtie2', '--very-sensitive', '-p', str(ncpu),\n",
    "                       '-X', '5000', '-k', '2', '-x', assembly,\n",
    "                       '-1', file_R1, '-2', file_R2,\n",
    "                       '-S', file_sam_genome_global]\n",
    "\n",
    "    handle_sam_report_genome_global = open(file_sam_report_genome_global, 'wb')\n",
    "\n",
    "    subprocess.call(bowtie2_command, stderr=handle_sam_report_genome_global)\n",
    "\n",
    "    handle_sam_report_genome_global.close()\n",
    "\n",
    "    # convert sam to bam\n",
    "    sam_to_bam_genome_global_command = ['samtools', 'view', '-Sb', file_sam_genome_global]\n",
    "\n",
    "    handle_file_bam_genome_global = open(file_bam_genome_global, 'wb')\n",
    "\n",
    "    subprocess.call(sam_to_bam_genome_global_command, stdout=handle_file_bam_genome_global)\n",
    "\n",
    "    # sort bam files\n",
    "    sort_bam_genome_global_command = ['samtools', 'sort', file_bam_genome_global, '-o', file_sorted_bam_genome_global]\n",
    "\n",
    "    subprocess.call(sort_bam_genome_global_command)\n",
    "\n",
    "    # Clean up\n",
    "    os.remove(file_sam_genome_global)\n",
    "    os.remove(file_bam_genome_global)\n",
    "\n",
    "    # Create bam index files\n",
    "    create_bam_genome_global_index_command = ['samtools', 'index', file_sorted_bam_genome_global]\n",
    "    subprocess.call(create_bam_genome_global_index_command)\n",
    "\n",
    "    os.chdir(initial_dir)\n",
    "\n",
    "################################################################################\n",
    "# Function to analyze global alignments to the genome\n",
    "# this genome analysis really needs to be done for the excel stuff I think\n",
    "################################################################################\n",
    "def analyze_alignments_genome_global(dir_sample, amplicon_info, min_MAPQ, min_AS,  file_genome_2bit):\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "\n",
    "    genome = twobitreader.TwoBitFile(file_genome_2bit)\n",
    "\n",
    "    exp_dir = create_filename(dir_sample, N7, N5, 'mainfolder')\n",
    "\n",
    "    file_UMI = create_filename(dir_sample, N7, N5, 'umifastqgz')\n",
    "    UMI_dict = create_barcode_dict(file_UMI)\n",
    "\n",
    "    results_folder = os.path.join(exp_dir, 'results')\n",
    "    if not os.path.exists(results_folder):\n",
    "        os.mkdir(results_folder)\n",
    "\n",
    "    results_file = create_filename(dir_sample, N7, N5, 'results_genomewide')\n",
    "\n",
    "    file_sorted_bam_genome_global = create_filename(dir_sample, N7, N5, 'sorted_bam_genome_global')\n",
    "\n",
    "    bam_in_alignment_file = pysam.AlignmentFile(file_sorted_bam_genome_global, 'rb')\n",
    "\n",
    "    bam_in_all = bam_in_alignment_file.fetch()\n",
    "\n",
    "    names_list_genome = []\n",
    "    UMI_list_genome = []\n",
    "    readcount = 0\n",
    "    for read in bam_in_all:\n",
    "        readcount += 1\n",
    "        if read.has_tag('AS'):\n",
    "            read_AS = read.get_tag('AS')\n",
    "        # We test first if the read is unmapped, otherwise read_AS would be undefined\n",
    "        if not read.is_unmapped and (read.mapping_quality >= min_MAPQ\n",
    "                                     and read_AS >= min_AS and not read.is_secondary):\n",
    "            UMI_list_genome.append(UMI_dict[read.query_name][0])\n",
    "            names_list_genome.append(read.query_name)\n",
    "    print('the number of alignments that were attempted to align', readcount)\n",
    "    names_list_target_only = []\n",
    "    UMI_list_target_only = []\n",
    "\n",
    "    fetch_window = 1000\n",
    "    fetch_chr = amplicon_info['chr']\n",
    "\n",
    "    if amplicon_info['strand'] == '+':  # This is the UDiTaS oligo strand\n",
    "        fetch_start = amplicon_info['start']\n",
    "        fetch_end = amplicon_info['end'] + fetch_window\n",
    "        if fetch_end > len(genome[amplicon_info['chr']]):\n",
    "            fetch_end = len(genome[amplicon_info['chr']])\n",
    "\n",
    "    elif amplicon_info['strand'] == '-':\n",
    "        fetch_start = amplicon_info['start'] - fetch_window\n",
    "        fetch_end = amplicon_info['end']\n",
    "        if fetch_start < 0:\n",
    "            fetch_start = 0\n",
    "\n",
    "    bam_in_target = bam_in_alignment_file.fetch(fetch_chr, fetch_start, fetch_end)\n",
    "\n",
    "    for read in bam_in_target:\n",
    "        if read.mapping_quality >= min_MAPQ and not read.is_unmapped and not read.is_secondary:\n",
    "            UMI_list_target_only.append(UMI_dict[read.query_name][0])\n",
    "            names_list_target_only.append(read.query_name)\n",
    "\n",
    "    genomewide_total_reads = len(set(names_list_genome))\n",
    "    genomewide_total_reads_collapsed = len(set(UMI_list_genome))\n",
    "    genomewide_target_only_reads = len(set(names_list_target_only))\n",
    "    genomewide_target_only_reads_collapsed = len(set(UMI_list_target_only))\n",
    "\n",
    "    results_df = pd.DataFrame({'genomewide_total_reads': [genomewide_total_reads],\n",
    "                               'genomewide_total_reads_collapsed': [genomewide_total_reads_collapsed],\n",
    "                               'genomewide_target_only_reads': [genomewide_target_only_reads],\n",
    "                               'genomewide_target_only_reads_collapsed': [genomewide_target_only_reads_collapsed]\n",
    "                               },\n",
    "                              columns=['genomewide_total_reads',\n",
    "                                       'genomewide_total_reads_collapsed',\n",
    "                                       'genomewide_target_only_reads',\n",
    "                                       'genomewide_target_only_reads_collapsed'])\n",
    "\n",
    "    results_df.to_excel(results_file)\n",
    "\n",
    "    return results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the allignment\n",
    "assembly = amplicon_info['genome']\n",
    "align_genome_global(directory, amplicon_info, assembly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of alignments that were attempted to align 580\n",
      "   genomewide_total_reads  genomewide_total_reads_collapsed  \\\n",
      "0                     225                               164   \n",
      "\n",
      "   genomewide_target_only_reads  genomewide_target_only_reads_collapsed  \n",
      "0                             1                                       1  \n"
     ]
    }
   ],
   "source": [
    "#Do the global alignment analysis\n",
    "results_genome_global_df = analyze_alignments_genome_global(directory, amplicon_info, min_MAPQ, min_AS,  file_genome_2bit)\n",
    "print(results_genome_global_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summerize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a function to count the amount of original files\n",
    "# I did not modify this from uditas\n",
    "\n",
    "################################################################################\n",
    "# Fast way to count reads, but only works on unix\n",
    "################################################################################\n",
    "def wc_unix(filename):\n",
    "    cat_out = subprocess.Popen(('zcat', filename), stdout=subprocess.PIPE)\n",
    "    return int(int(subprocess.check_output([\"wc\", \"-l\"], stdin=cat_out.stdout).split()[0])/4.)\n",
    "################################################################################\n",
    "# Function to count reads\n",
    "#used in uditas.py to count total input reads\n",
    "################################################################################\n",
    "def count_reads(dir_sample, amplicon_info):\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "\n",
    "    read_counts_file = create_filename(dir_sample, N7, N5, 'read_counts')\n",
    "    file_cutadapt_R1 = create_filename(dir_sample, N7, N5, 'R1trimmed')\n",
    "\n",
    "    rc = wc_unix(file_cutadapt_R1)\n",
    "    df = pd.DataFrame({'read_count': [rc]})\n",
    "\n",
    "    df.to_excel(read_counts_file)\n",
    "\n",
    "    return rc\n",
    "\n",
    "################################################################################\n",
    "#  Function to get the percentages for the alignment of all reads mapped to ALL plasmid, amplicons and genomewide\n",
    "################################################################################\n",
    "def get_summary_all_alignments(dir_sample, amplicon_info, read_count, result_plasmid_df,\n",
    "               result_reads_in_all_amplicons_df, results_genome_global_df):\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "\n",
    "    summary_all_alignments_file = create_filename(dir_sample, N7, N5, 'summary_all_alignments')\n",
    "\n",
    "    summary_all_alignments = pd.concat([read_count, result_plasmid_df,\n",
    "               result_reads_in_all_amplicons_df, results_genome_global_df], axis=1)\n",
    "\n",
    "    total_reads_list = [k for k in summary_all_alignments.keys() if str(k).endswith('_total_reads')]\n",
    "\n",
    "    summary_all_alignments['total_aligned'] = summary_all_alignments[total_reads_list].sum(axis=1)\n",
    "\n",
    "    total_reads_collapsed_list = [k for k in summary_all_alignments.keys() if str(k).endswith('_total_reads_collapsed')]\n",
    "\n",
    "    summary_all_alignments['total_aligned_collapsed'] = summary_all_alignments[total_reads_collapsed_list].sum(axis=1)\n",
    "\n",
    "    summary_all_alignments['percent_aligned'] = 100 * (summary_all_alignments['total_aligned'] /\n",
    "                                                       summary_all_alignments['read_count'])\n",
    "    summary_all_alignments['percent_aligned_all_amplicons'] = 100 * (summary_all_alignments['all_amplicons_total_reads'] /\n",
    "                                                        summary_all_alignments['total_aligned'])\n",
    "    summary_all_alignments.to_excel(summary_all_alignments_file, index=False)\n",
    "\n",
    "    return summary_all_alignments\n",
    "\n",
    "################################################################################\n",
    "# Function to summarize counts into all amplicons\n",
    "################################################################################\n",
    "def summarize_results(results):\n",
    "\n",
    "    total_reads_list = [k for k in results.keys() if str(k).endswith('_total_reads')]\n",
    "    total_reads_collapsed_list = [k for k in results.keys() if str(k).endswith('_total_reads_collapsed')]\n",
    "\n",
    "    results['total_aligned_junctions'] = results[total_reads_list].sum(axis=1)\n",
    "\n",
    "    for k in total_reads_list:\n",
    "        # We add np.finfo(float).eps to prevent dividing by 0\n",
    "        results[k + '_percent'] = 100 * results[k] / (results['total_aligned_junctions'] +\n",
    "                                                      np.finfo(float).eps)\n",
    "\n",
    "    results['total_aligned_junctions_collapsed'] = results[total_reads_collapsed_list].sum(axis=1)\n",
    "\n",
    "    for k in total_reads_collapsed_list:\n",
    "        results[k + '_percent'] = 100 * results[k] / (results['total_aligned_junctions_collapsed'] +\n",
    "                                                      np.finfo(float).eps)\n",
    "\n",
    "    return results\n",
    "\n",
    "#######################################################################################\n",
    "# We pivot the table using melt for easier visualization with other tools like Tableau\n",
    "#######################################################################################\n",
    "def melt_results(results_summary_with_experiments):\n",
    "\n",
    "    melt_list = [k for k in results_summary_with_experiments.keys() if\n",
    "                 str(k).endswith('_total_reads_collapsed_percent')]\n",
    "\n",
    "    frozen_list = list(results_summary_with_experiments)\n",
    "\n",
    "    for el in melt_list:\n",
    "        frozen_list.remove(el)\n",
    "\n",
    "    results_out = pd.melt(results_summary_with_experiments,\n",
    "                          value_vars=melt_list,\n",
    "                          id_vars=frozen_list, var_name='Type', value_name='Percent Editing')\n",
    "\n",
    "    return results_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132279.0"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_count = pd.DataFrame()\n",
    "read_count.loc[0,'read_count'] = count_reads(directory, amplicon_info)\n",
    "read_count.loc[0,'read_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>read_count</th>\n",
       "      <th>target_plus_plasmid_total_reads</th>\n",
       "      <th>target_plus_plasmid_total_reads_collapsed</th>\n",
       "      <th>plasmid_only_total_reads</th>\n",
       "      <th>plasmid_only_total_reads_collapsed</th>\n",
       "      <th>all_amplicons_total_reads</th>\n",
       "      <th>all_amplicons_total_reads_collapsed</th>\n",
       "      <th>genomewide_total_reads</th>\n",
       "      <th>genomewide_total_reads_collapsed</th>\n",
       "      <th>genomewide_target_only_reads</th>\n",
       "      <th>genomewide_target_only_reads_collapsed</th>\n",
       "      <th>total_aligned</th>\n",
       "      <th>total_aligned_collapsed</th>\n",
       "      <th>percent_aligned</th>\n",
       "      <th>percent_aligned_all_amplicons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132279.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6758</td>\n",
       "      <td>88</td>\n",
       "      <td>86945</td>\n",
       "      <td>1888</td>\n",
       "      <td>225</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>93928</td>\n",
       "      <td>2140</td>\n",
       "      <td>71.007492</td>\n",
       "      <td>92.565582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   read_count  target_plus_plasmid_total_reads  \\\n",
       "0    132279.0                                0   \n",
       "\n",
       "   target_plus_plasmid_total_reads_collapsed  plasmid_only_total_reads  \\\n",
       "0                                          0                      6758   \n",
       "\n",
       "   plasmid_only_total_reads_collapsed  all_amplicons_total_reads  \\\n",
       "0                                  88                      86945   \n",
       "\n",
       "   all_amplicons_total_reads_collapsed  genomewide_total_reads  \\\n",
       "0                                 1888                     225   \n",
       "\n",
       "   genomewide_total_reads_collapsed  genomewide_target_only_reads  \\\n",
       "0                               164                             1   \n",
       "\n",
       "   genomewide_target_only_reads_collapsed  total_aligned  \\\n",
       "0                                       1          93928   \n",
       "\n",
       "   total_aligned_collapsed  percent_aligned  percent_aligned_all_amplicons  \n",
       "0                     2140        71.007492                      92.565582  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summerize the data\n",
    "\n",
    "summary_all_alignments = get_summary_all_alignments(directory, amplicon_info, read_count.loc[[0]], result_plasmid_df, result_reads_in_all_amplicons_df, results_genome_global_df)\n",
    "summary_all_alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_alignments_junction = pd.concat([result_amplicon_df, result_plasmid_df], axis=1)\n",
    "sample_info_filename = os.path.join(directory, 'sample_info.csv')\n",
    "\n",
    "experiments = pd.read_csv(sample_info_filename)\n",
    "\n",
    "\n",
    "results_summary = summarize_results(results_alignments_junction)\n",
    "#this outputs it in a directory above the N501_701 folder as a summary file. Need to label it or it will be overwritten by next tone\n",
    "results_summary_with_experiments = pd.concat([experiments, results_summary], axis=1)\n",
    "\n",
    "results_summary_with_experiments.to_excel(os.path.join(directory, 'results_summary.xlsx'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NGS_req-ID</th>\n",
       "      <th>name</th>\n",
       "      <th>Sample</th>\n",
       "      <th>description</th>\n",
       "      <th>Control sample (Y/N)</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Dilution</th>\n",
       "      <th>Cell name_type</th>\n",
       "      <th>UMI_Len</th>\n",
       "      <th>IndexI7Primer</th>\n",
       "      <th>...</th>\n",
       "      <th>doner_tail_tail_cut1_total_reads_percent</th>\n",
       "      <th>doner_head_tail_cut1_total_reads_percent</th>\n",
       "      <th>doner_head_head_cut1_total_reads_percent</th>\n",
       "      <th>1a_1a_cut1_total_reads_percent</th>\n",
       "      <th>2b_2b_cut1_total_reads_percent</th>\n",
       "      <th>target_plus_plasmid_total_reads_percent</th>\n",
       "      <th>plasmid_only_total_reads_percent</th>\n",
       "      <th>total_aligned_junctions_collapsed</th>\n",
       "      <th>Type</th>\n",
       "      <th>Percent Editing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbF</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.375797</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>wt_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbR</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE369</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wt_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_mCh</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE370</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wt_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_bpa</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE371</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wt_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE372</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wt_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE373</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wt_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbF</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.375797</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>wt_cut2_total_reads_collapsed_percent</td>\n",
       "      <td>17.879098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbR</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE369</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wt_cut2_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_mCh</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE370</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wt_cut2_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_bpa</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE371</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wt_cut2_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE372</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wt_cut2_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE373</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wt_cut2_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbF</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.375797</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>large_deletion_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>29.149590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbR</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE369</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large_deletion_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_mCh</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE370</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large_deletion_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_bpa</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE371</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large_deletion_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE372</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large_deletion_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE373</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large_deletion_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbF</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.375797</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>large_inversion_cut1_total_reads_collapsed_per...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbR</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE369</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large_inversion_cut1_total_reads_collapsed_per...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_mCh</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE370</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large_inversion_cut1_total_reads_collapsed_per...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_bpa</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE371</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large_inversion_cut1_total_reads_collapsed_per...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE372</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large_inversion_cut1_total_reads_collapsed_per...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE373</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large_inversion_cut1_total_reads_collapsed_per...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbF</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.375797</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>large_inversion_cut2_total_reads_collapsed_per...</td>\n",
       "      <td>9.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbR</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE369</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large_inversion_cut2_total_reads_collapsed_per...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_mCh</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE370</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large_inversion_cut2_total_reads_collapsed_per...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_bpa</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE371</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large_inversion_cut2_total_reads_collapsed_per...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE372</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large_inversion_cut2_total_reads_collapsed_per...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE373</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large_inversion_cut2_total_reads_collapsed_per...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbF</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.375797</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>doner_head_head_cut1_total_reads_collapsed_per...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbR</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE369</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doner_head_head_cut1_total_reads_collapsed_per...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_mCh</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE370</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doner_head_head_cut1_total_reads_collapsed_per...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_bpa</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE371</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doner_head_head_cut1_total_reads_collapsed_per...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE372</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doner_head_head_cut1_total_reads_collapsed_per...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE373</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doner_head_head_cut1_total_reads_collapsed_per...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbF</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.375797</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>1a_1a_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbR</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE369</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1a_1a_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_mCh</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE370</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1a_1a_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_bpa</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE371</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1a_1a_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE372</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1a_1a_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE373</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1a_1a_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbF</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.375797</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>2b_2b_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbR</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE369</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2b_2b_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_mCh</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE370</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2b_2b_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_bpa</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE371</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2b_2b_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE372</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2b_2b_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE373</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2b_2b_cut1_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbF</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.375797</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>target_plus_plasmid_total_reads_collapsed_percent</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbR</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE369</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>target_plus_plasmid_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_mCh</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE370</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>target_plus_plasmid_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_bpa</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE371</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>target_plus_plasmid_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE372</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>target_plus_plasmid_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE373</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>target_plus_plasmid_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbF</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.375797</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>plasmid_only_total_reads_collapsed_percent</td>\n",
       "      <td>4.508197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_polbR</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE369</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>plasmid_only_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_mCh</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE370</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>plasmid_only_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_Pol50_bpa</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE371</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>plasmid_only_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbF</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE372</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>plasmid_only_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>A000H2GWGF</td>\n",
       "      <td>Tn5_WT_pbR</td>\n",
       "      <td>Polb</td>\n",
       "      <td>MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K562</td>\n",
       "      <td>NNNNNNNNNN</td>\n",
       "      <td>prE373</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>plasmid_only_total_reads_collapsed_percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    NGS_req-ID           name Sample  \\\n",
       "0   A000H2GWGF  Tn5_Pol50_pbF   Polb   \n",
       "1   A000H2GWGF  Tn5_Pol50_pbR   Polb   \n",
       "2   A000H2GWGF  Tn5_Pol50_mCh   Polb   \n",
       "3   A000H2GWGF  Tn5_Pol50_bpa   Polb   \n",
       "4   A000H2GWGF     Tn5_WT_pbF   Polb   \n",
       "5   A000H2GWGF     Tn5_WT_pbR   Polb   \n",
       "6   A000H2GWGF  Tn5_Pol50_pbF   Polb   \n",
       "7   A000H2GWGF  Tn5_Pol50_pbR   Polb   \n",
       "8   A000H2GWGF  Tn5_Pol50_mCh   Polb   \n",
       "9   A000H2GWGF  Tn5_Pol50_bpa   Polb   \n",
       "10  A000H2GWGF     Tn5_WT_pbF   Polb   \n",
       "11  A000H2GWGF     Tn5_WT_pbR   Polb   \n",
       "12  A000H2GWGF  Tn5_Pol50_pbF   Polb   \n",
       "13  A000H2GWGF  Tn5_Pol50_pbR   Polb   \n",
       "14  A000H2GWGF  Tn5_Pol50_mCh   Polb   \n",
       "15  A000H2GWGF  Tn5_Pol50_bpa   Polb   \n",
       "16  A000H2GWGF     Tn5_WT_pbF   Polb   \n",
       "17  A000H2GWGF     Tn5_WT_pbR   Polb   \n",
       "18  A000H2GWGF  Tn5_Pol50_pbF   Polb   \n",
       "19  A000H2GWGF  Tn5_Pol50_pbR   Polb   \n",
       "20  A000H2GWGF  Tn5_Pol50_mCh   Polb   \n",
       "21  A000H2GWGF  Tn5_Pol50_bpa   Polb   \n",
       "22  A000H2GWGF     Tn5_WT_pbF   Polb   \n",
       "23  A000H2GWGF     Tn5_WT_pbR   Polb   \n",
       "24  A000H2GWGF  Tn5_Pol50_pbF   Polb   \n",
       "25  A000H2GWGF  Tn5_Pol50_pbR   Polb   \n",
       "26  A000H2GWGF  Tn5_Pol50_mCh   Polb   \n",
       "27  A000H2GWGF  Tn5_Pol50_bpa   Polb   \n",
       "28  A000H2GWGF     Tn5_WT_pbF   Polb   \n",
       "29  A000H2GWGF     Tn5_WT_pbR   Polb   \n",
       "..         ...            ...    ...   \n",
       "66  A000H2GWGF  Tn5_Pol50_pbF   Polb   \n",
       "67  A000H2GWGF  Tn5_Pol50_pbR   Polb   \n",
       "68  A000H2GWGF  Tn5_Pol50_mCh   Polb   \n",
       "69  A000H2GWGF  Tn5_Pol50_bpa   Polb   \n",
       "70  A000H2GWGF     Tn5_WT_pbF   Polb   \n",
       "71  A000H2GWGF     Tn5_WT_pbR   Polb   \n",
       "72  A000H2GWGF  Tn5_Pol50_pbF   Polb   \n",
       "73  A000H2GWGF  Tn5_Pol50_pbR   Polb   \n",
       "74  A000H2GWGF  Tn5_Pol50_mCh   Polb   \n",
       "75  A000H2GWGF  Tn5_Pol50_bpa   Polb   \n",
       "76  A000H2GWGF     Tn5_WT_pbF   Polb   \n",
       "77  A000H2GWGF     Tn5_WT_pbR   Polb   \n",
       "78  A000H2GWGF  Tn5_Pol50_pbF   Polb   \n",
       "79  A000H2GWGF  Tn5_Pol50_pbR   Polb   \n",
       "80  A000H2GWGF  Tn5_Pol50_mCh   Polb   \n",
       "81  A000H2GWGF  Tn5_Pol50_bpa   Polb   \n",
       "82  A000H2GWGF     Tn5_WT_pbF   Polb   \n",
       "83  A000H2GWGF     Tn5_WT_pbR   Polb   \n",
       "84  A000H2GWGF  Tn5_Pol50_pbF   Polb   \n",
       "85  A000H2GWGF  Tn5_Pol50_pbR   Polb   \n",
       "86  A000H2GWGF  Tn5_Pol50_mCh   Polb   \n",
       "87  A000H2GWGF  Tn5_Pol50_bpa   Polb   \n",
       "88  A000H2GWGF     Tn5_WT_pbF   Polb   \n",
       "89  A000H2GWGF     Tn5_WT_pbR   Polb   \n",
       "90  A000H2GWGF  Tn5_Pol50_pbF   Polb   \n",
       "91  A000H2GWGF  Tn5_Pol50_pbR   Polb   \n",
       "92  A000H2GWGF  Tn5_Pol50_mCh   Polb   \n",
       "93  A000H2GWGF  Tn5_Pol50_bpa   Polb   \n",
       "94  A000H2GWGF     Tn5_WT_pbF   Polb   \n",
       "95  A000H2GWGF     Tn5_WT_pbR   Polb   \n",
       "\n",
       "                                          description Control sample (Y/N)  \\\n",
       "0         MiniSeq_K562_PolbHIROS_50per_unsorted_polbF                    N   \n",
       "1         MiniSeq_K562_PolbHIROS_50per_unsorted_polbR                    N   \n",
       "2   MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...                    N   \n",
       "3   MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd                    N   \n",
       "4   MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "5   MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "6         MiniSeq_K562_PolbHIROS_50per_unsorted_polbF                    N   \n",
       "7         MiniSeq_K562_PolbHIROS_50per_unsorted_polbR                    N   \n",
       "8   MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...                    N   \n",
       "9   MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd                    N   \n",
       "10  MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "11  MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "12        MiniSeq_K562_PolbHIROS_50per_unsorted_polbF                    N   \n",
       "13        MiniSeq_K562_PolbHIROS_50per_unsorted_polbR                    N   \n",
       "14  MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...                    N   \n",
       "15  MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd                    N   \n",
       "16  MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "17  MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "18        MiniSeq_K562_PolbHIROS_50per_unsorted_polbF                    N   \n",
       "19        MiniSeq_K562_PolbHIROS_50per_unsorted_polbR                    N   \n",
       "20  MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...                    N   \n",
       "21  MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd                    N   \n",
       "22  MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "23  MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "24        MiniSeq_K562_PolbHIROS_50per_unsorted_polbF                    N   \n",
       "25        MiniSeq_K562_PolbHIROS_50per_unsorted_polbR                    N   \n",
       "26  MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...                    N   \n",
       "27  MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd                    N   \n",
       "28  MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "29  MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "..                                                ...                  ...   \n",
       "66        MiniSeq_K562_PolbHIROS_50per_unsorted_polbF                    N   \n",
       "67        MiniSeq_K562_PolbHIROS_50per_unsorted_polbR                    N   \n",
       "68  MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...                    N   \n",
       "69  MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd                    N   \n",
       "70  MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "71  MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "72        MiniSeq_K562_PolbHIROS_50per_unsorted_polbF                    N   \n",
       "73        MiniSeq_K562_PolbHIROS_50per_unsorted_polbR                    N   \n",
       "74  MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...                    N   \n",
       "75  MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd                    N   \n",
       "76  MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "77  MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "78        MiniSeq_K562_PolbHIROS_50per_unsorted_polbF                    N   \n",
       "79        MiniSeq_K562_PolbHIROS_50per_unsorted_polbR                    N   \n",
       "80  MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...                    N   \n",
       "81  MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd                    N   \n",
       "82  MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "83  MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "84        MiniSeq_K562_PolbHIROS_50per_unsorted_polbF                    N   \n",
       "85        MiniSeq_K562_PolbHIROS_50per_unsorted_polbR                    N   \n",
       "86  MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...                    N   \n",
       "87  MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd                    N   \n",
       "88  MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "89  MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "90        MiniSeq_K562_PolbHIROS_50per_unsorted_polbF                    N   \n",
       "91        MiniSeq_K562_PolbHIROS_50per_unsorted_polbR                    N   \n",
       "92  MiniSeq_K562_PolbHIROS_50per_unsorted_mCherryp...                    N   \n",
       "93  MiniSeq_K562_PolbHIROS_50per_unsorted_mCherry_Fwd                    N   \n",
       "94  MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "95  MiniSeq_K562_PolbHIROS_Wtcontaminated_w_50per_...                    N   \n",
       "\n",
       "    Notes  Dilution Cell name_type     UMI_Len IndexI7Primer  ...  \\\n",
       "0     NaN       NaN           K562  NNNNNNNNNN        prE368  ...   \n",
       "1     NaN       NaN           K562  NNNNNNNNNN        prE369  ...   \n",
       "2     NaN       NaN           K562  NNNNNNNNNN        prE370  ...   \n",
       "3     NaN       NaN           K562  NNNNNNNNNN        prE371  ...   \n",
       "4     NaN       NaN           K562  NNNNNNNNNN        prE372  ...   \n",
       "5     NaN       NaN           K562  NNNNNNNNNN        prE373  ...   \n",
       "6     NaN       NaN           K562  NNNNNNNNNN        prE368  ...   \n",
       "7     NaN       NaN           K562  NNNNNNNNNN        prE369  ...   \n",
       "8     NaN       NaN           K562  NNNNNNNNNN        prE370  ...   \n",
       "9     NaN       NaN           K562  NNNNNNNNNN        prE371  ...   \n",
       "10    NaN       NaN           K562  NNNNNNNNNN        prE372  ...   \n",
       "11    NaN       NaN           K562  NNNNNNNNNN        prE373  ...   \n",
       "12    NaN       NaN           K562  NNNNNNNNNN        prE368  ...   \n",
       "13    NaN       NaN           K562  NNNNNNNNNN        prE369  ...   \n",
       "14    NaN       NaN           K562  NNNNNNNNNN        prE370  ...   \n",
       "15    NaN       NaN           K562  NNNNNNNNNN        prE371  ...   \n",
       "16    NaN       NaN           K562  NNNNNNNNNN        prE372  ...   \n",
       "17    NaN       NaN           K562  NNNNNNNNNN        prE373  ...   \n",
       "18    NaN       NaN           K562  NNNNNNNNNN        prE368  ...   \n",
       "19    NaN       NaN           K562  NNNNNNNNNN        prE369  ...   \n",
       "20    NaN       NaN           K562  NNNNNNNNNN        prE370  ...   \n",
       "21    NaN       NaN           K562  NNNNNNNNNN        prE371  ...   \n",
       "22    NaN       NaN           K562  NNNNNNNNNN        prE372  ...   \n",
       "23    NaN       NaN           K562  NNNNNNNNNN        prE373  ...   \n",
       "24    NaN       NaN           K562  NNNNNNNNNN        prE368  ...   \n",
       "25    NaN       NaN           K562  NNNNNNNNNN        prE369  ...   \n",
       "26    NaN       NaN           K562  NNNNNNNNNN        prE370  ...   \n",
       "27    NaN       NaN           K562  NNNNNNNNNN        prE371  ...   \n",
       "28    NaN       NaN           K562  NNNNNNNNNN        prE372  ...   \n",
       "29    NaN       NaN           K562  NNNNNNNNNN        prE373  ...   \n",
       "..    ...       ...            ...         ...           ...  ...   \n",
       "66    NaN       NaN           K562  NNNNNNNNNN        prE368  ...   \n",
       "67    NaN       NaN           K562  NNNNNNNNNN        prE369  ...   \n",
       "68    NaN       NaN           K562  NNNNNNNNNN        prE370  ...   \n",
       "69    NaN       NaN           K562  NNNNNNNNNN        prE371  ...   \n",
       "70    NaN       NaN           K562  NNNNNNNNNN        prE372  ...   \n",
       "71    NaN       NaN           K562  NNNNNNNNNN        prE373  ...   \n",
       "72    NaN       NaN           K562  NNNNNNNNNN        prE368  ...   \n",
       "73    NaN       NaN           K562  NNNNNNNNNN        prE369  ...   \n",
       "74    NaN       NaN           K562  NNNNNNNNNN        prE370  ...   \n",
       "75    NaN       NaN           K562  NNNNNNNNNN        prE371  ...   \n",
       "76    NaN       NaN           K562  NNNNNNNNNN        prE372  ...   \n",
       "77    NaN       NaN           K562  NNNNNNNNNN        prE373  ...   \n",
       "78    NaN       NaN           K562  NNNNNNNNNN        prE368  ...   \n",
       "79    NaN       NaN           K562  NNNNNNNNNN        prE369  ...   \n",
       "80    NaN       NaN           K562  NNNNNNNNNN        prE370  ...   \n",
       "81    NaN       NaN           K562  NNNNNNNNNN        prE371  ...   \n",
       "82    NaN       NaN           K562  NNNNNNNNNN        prE372  ...   \n",
       "83    NaN       NaN           K562  NNNNNNNNNN        prE373  ...   \n",
       "84    NaN       NaN           K562  NNNNNNNNNN        prE368  ...   \n",
       "85    NaN       NaN           K562  NNNNNNNNNN        prE369  ...   \n",
       "86    NaN       NaN           K562  NNNNNNNNNN        prE370  ...   \n",
       "87    NaN       NaN           K562  NNNNNNNNNN        prE371  ...   \n",
       "88    NaN       NaN           K562  NNNNNNNNNN        prE372  ...   \n",
       "89    NaN       NaN           K562  NNNNNNNNNN        prE373  ...   \n",
       "90    NaN       NaN           K562  NNNNNNNNNN        prE368  ...   \n",
       "91    NaN       NaN           K562  NNNNNNNNNN        prE369  ...   \n",
       "92    NaN       NaN           K562  NNNNNNNNNN        prE370  ...   \n",
       "93    NaN       NaN           K562  NNNNNNNNNN        prE371  ...   \n",
       "94    NaN       NaN           K562  NNNNNNNNNN        prE372  ...   \n",
       "95    NaN       NaN           K562  NNNNNNNNNN        prE373  ...   \n",
       "\n",
       "   doner_tail_tail_cut1_total_reads_percent  \\\n",
       "0                                       0.0   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "5                                       NaN   \n",
       "6                                       0.0   \n",
       "7                                       NaN   \n",
       "8                                       NaN   \n",
       "9                                       NaN   \n",
       "10                                      NaN   \n",
       "11                                      NaN   \n",
       "12                                      0.0   \n",
       "13                                      NaN   \n",
       "14                                      NaN   \n",
       "15                                      NaN   \n",
       "16                                      NaN   \n",
       "17                                      NaN   \n",
       "18                                      0.0   \n",
       "19                                      NaN   \n",
       "20                                      NaN   \n",
       "21                                      NaN   \n",
       "22                                      NaN   \n",
       "23                                      NaN   \n",
       "24                                      0.0   \n",
       "25                                      NaN   \n",
       "26                                      NaN   \n",
       "27                                      NaN   \n",
       "28                                      NaN   \n",
       "29                                      NaN   \n",
       "..                                      ...   \n",
       "66                                      0.0   \n",
       "67                                      NaN   \n",
       "68                                      NaN   \n",
       "69                                      NaN   \n",
       "70                                      NaN   \n",
       "71                                      NaN   \n",
       "72                                      0.0   \n",
       "73                                      NaN   \n",
       "74                                      NaN   \n",
       "75                                      NaN   \n",
       "76                                      NaN   \n",
       "77                                      NaN   \n",
       "78                                      0.0   \n",
       "79                                      NaN   \n",
       "80                                      NaN   \n",
       "81                                      NaN   \n",
       "82                                      NaN   \n",
       "83                                      NaN   \n",
       "84                                      0.0   \n",
       "85                                      NaN   \n",
       "86                                      NaN   \n",
       "87                                      NaN   \n",
       "88                                      NaN   \n",
       "89                                      NaN   \n",
       "90                                      0.0   \n",
       "91                                      NaN   \n",
       "92                                      NaN   \n",
       "93                                      NaN   \n",
       "94                                      NaN   \n",
       "95                                      NaN   \n",
       "\n",
       "   doner_head_tail_cut1_total_reads_percent  \\\n",
       "0                                       0.0   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "5                                       NaN   \n",
       "6                                       0.0   \n",
       "7                                       NaN   \n",
       "8                                       NaN   \n",
       "9                                       NaN   \n",
       "10                                      NaN   \n",
       "11                                      NaN   \n",
       "12                                      0.0   \n",
       "13                                      NaN   \n",
       "14                                      NaN   \n",
       "15                                      NaN   \n",
       "16                                      NaN   \n",
       "17                                      NaN   \n",
       "18                                      0.0   \n",
       "19                                      NaN   \n",
       "20                                      NaN   \n",
       "21                                      NaN   \n",
       "22                                      NaN   \n",
       "23                                      NaN   \n",
       "24                                      0.0   \n",
       "25                                      NaN   \n",
       "26                                      NaN   \n",
       "27                                      NaN   \n",
       "28                                      NaN   \n",
       "29                                      NaN   \n",
       "..                                      ...   \n",
       "66                                      0.0   \n",
       "67                                      NaN   \n",
       "68                                      NaN   \n",
       "69                                      NaN   \n",
       "70                                      NaN   \n",
       "71                                      NaN   \n",
       "72                                      0.0   \n",
       "73                                      NaN   \n",
       "74                                      NaN   \n",
       "75                                      NaN   \n",
       "76                                      NaN   \n",
       "77                                      NaN   \n",
       "78                                      0.0   \n",
       "79                                      NaN   \n",
       "80                                      NaN   \n",
       "81                                      NaN   \n",
       "82                                      NaN   \n",
       "83                                      NaN   \n",
       "84                                      0.0   \n",
       "85                                      NaN   \n",
       "86                                      NaN   \n",
       "87                                      NaN   \n",
       "88                                      NaN   \n",
       "89                                      NaN   \n",
       "90                                      0.0   \n",
       "91                                      NaN   \n",
       "92                                      NaN   \n",
       "93                                      NaN   \n",
       "94                                      NaN   \n",
       "95                                      NaN   \n",
       "\n",
       "   doner_head_head_cut1_total_reads_percent 1a_1a_cut1_total_reads_percent  \\\n",
       "0                                       0.0                            0.0   \n",
       "1                                       NaN                            NaN   \n",
       "2                                       NaN                            NaN   \n",
       "3                                       NaN                            NaN   \n",
       "4                                       NaN                            NaN   \n",
       "5                                       NaN                            NaN   \n",
       "6                                       0.0                            0.0   \n",
       "7                                       NaN                            NaN   \n",
       "8                                       NaN                            NaN   \n",
       "9                                       NaN                            NaN   \n",
       "10                                      NaN                            NaN   \n",
       "11                                      NaN                            NaN   \n",
       "12                                      0.0                            0.0   \n",
       "13                                      NaN                            NaN   \n",
       "14                                      NaN                            NaN   \n",
       "15                                      NaN                            NaN   \n",
       "16                                      NaN                            NaN   \n",
       "17                                      NaN                            NaN   \n",
       "18                                      0.0                            0.0   \n",
       "19                                      NaN                            NaN   \n",
       "20                                      NaN                            NaN   \n",
       "21                                      NaN                            NaN   \n",
       "22                                      NaN                            NaN   \n",
       "23                                      NaN                            NaN   \n",
       "24                                      0.0                            0.0   \n",
       "25                                      NaN                            NaN   \n",
       "26                                      NaN                            NaN   \n",
       "27                                      NaN                            NaN   \n",
       "28                                      NaN                            NaN   \n",
       "29                                      NaN                            NaN   \n",
       "..                                      ...                            ...   \n",
       "66                                      0.0                            0.0   \n",
       "67                                      NaN                            NaN   \n",
       "68                                      NaN                            NaN   \n",
       "69                                      NaN                            NaN   \n",
       "70                                      NaN                            NaN   \n",
       "71                                      NaN                            NaN   \n",
       "72                                      0.0                            0.0   \n",
       "73                                      NaN                            NaN   \n",
       "74                                      NaN                            NaN   \n",
       "75                                      NaN                            NaN   \n",
       "76                                      NaN                            NaN   \n",
       "77                                      NaN                            NaN   \n",
       "78                                      0.0                            0.0   \n",
       "79                                      NaN                            NaN   \n",
       "80                                      NaN                            NaN   \n",
       "81                                      NaN                            NaN   \n",
       "82                                      NaN                            NaN   \n",
       "83                                      NaN                            NaN   \n",
       "84                                      0.0                            0.0   \n",
       "85                                      NaN                            NaN   \n",
       "86                                      NaN                            NaN   \n",
       "87                                      NaN                            NaN   \n",
       "88                                      NaN                            NaN   \n",
       "89                                      NaN                            NaN   \n",
       "90                                      0.0                            0.0   \n",
       "91                                      NaN                            NaN   \n",
       "92                                      NaN                            NaN   \n",
       "93                                      NaN                            NaN   \n",
       "94                                      NaN                            NaN   \n",
       "95                                      NaN                            NaN   \n",
       "\n",
       "   2b_2b_cut1_total_reads_percent target_plus_plasmid_total_reads_percent  \\\n",
       "0                             0.0                                     0.0   \n",
       "1                             NaN                                     NaN   \n",
       "2                             NaN                                     NaN   \n",
       "3                             NaN                                     NaN   \n",
       "4                             NaN                                     NaN   \n",
       "5                             NaN                                     NaN   \n",
       "6                             0.0                                     0.0   \n",
       "7                             NaN                                     NaN   \n",
       "8                             NaN                                     NaN   \n",
       "9                             NaN                                     NaN   \n",
       "10                            NaN                                     NaN   \n",
       "11                            NaN                                     NaN   \n",
       "12                            0.0                                     0.0   \n",
       "13                            NaN                                     NaN   \n",
       "14                            NaN                                     NaN   \n",
       "15                            NaN                                     NaN   \n",
       "16                            NaN                                     NaN   \n",
       "17                            NaN                                     NaN   \n",
       "18                            0.0                                     0.0   \n",
       "19                            NaN                                     NaN   \n",
       "20                            NaN                                     NaN   \n",
       "21                            NaN                                     NaN   \n",
       "22                            NaN                                     NaN   \n",
       "23                            NaN                                     NaN   \n",
       "24                            0.0                                     0.0   \n",
       "25                            NaN                                     NaN   \n",
       "26                            NaN                                     NaN   \n",
       "27                            NaN                                     NaN   \n",
       "28                            NaN                                     NaN   \n",
       "29                            NaN                                     NaN   \n",
       "..                            ...                                     ...   \n",
       "66                            0.0                                     0.0   \n",
       "67                            NaN                                     NaN   \n",
       "68                            NaN                                     NaN   \n",
       "69                            NaN                                     NaN   \n",
       "70                            NaN                                     NaN   \n",
       "71                            NaN                                     NaN   \n",
       "72                            0.0                                     0.0   \n",
       "73                            NaN                                     NaN   \n",
       "74                            NaN                                     NaN   \n",
       "75                            NaN                                     NaN   \n",
       "76                            NaN                                     NaN   \n",
       "77                            NaN                                     NaN   \n",
       "78                            0.0                                     0.0   \n",
       "79                            NaN                                     NaN   \n",
       "80                            NaN                                     NaN   \n",
       "81                            NaN                                     NaN   \n",
       "82                            NaN                                     NaN   \n",
       "83                            NaN                                     NaN   \n",
       "84                            0.0                                     0.0   \n",
       "85                            NaN                                     NaN   \n",
       "86                            NaN                                     NaN   \n",
       "87                            NaN                                     NaN   \n",
       "88                            NaN                                     NaN   \n",
       "89                            NaN                                     NaN   \n",
       "90                            0.0                                     0.0   \n",
       "91                            NaN                                     NaN   \n",
       "92                            NaN                                     NaN   \n",
       "93                            NaN                                     NaN   \n",
       "94                            NaN                                     NaN   \n",
       "95                            NaN                                     NaN   \n",
       "\n",
       "   plasmid_only_total_reads_percent total_aligned_junctions_collapsed  \\\n",
       "0                          7.375797                            1952.0   \n",
       "1                               NaN                               NaN   \n",
       "2                               NaN                               NaN   \n",
       "3                               NaN                               NaN   \n",
       "4                               NaN                               NaN   \n",
       "5                               NaN                               NaN   \n",
       "6                          7.375797                            1952.0   \n",
       "7                               NaN                               NaN   \n",
       "8                               NaN                               NaN   \n",
       "9                               NaN                               NaN   \n",
       "10                              NaN                               NaN   \n",
       "11                              NaN                               NaN   \n",
       "12                         7.375797                            1952.0   \n",
       "13                              NaN                               NaN   \n",
       "14                              NaN                               NaN   \n",
       "15                              NaN                               NaN   \n",
       "16                              NaN                               NaN   \n",
       "17                              NaN                               NaN   \n",
       "18                         7.375797                            1952.0   \n",
       "19                              NaN                               NaN   \n",
       "20                              NaN                               NaN   \n",
       "21                              NaN                               NaN   \n",
       "22                              NaN                               NaN   \n",
       "23                              NaN                               NaN   \n",
       "24                         7.375797                            1952.0   \n",
       "25                              NaN                               NaN   \n",
       "26                              NaN                               NaN   \n",
       "27                              NaN                               NaN   \n",
       "28                              NaN                               NaN   \n",
       "29                              NaN                               NaN   \n",
       "..                              ...                               ...   \n",
       "66                         7.375797                            1952.0   \n",
       "67                              NaN                               NaN   \n",
       "68                              NaN                               NaN   \n",
       "69                              NaN                               NaN   \n",
       "70                              NaN                               NaN   \n",
       "71                              NaN                               NaN   \n",
       "72                         7.375797                            1952.0   \n",
       "73                              NaN                               NaN   \n",
       "74                              NaN                               NaN   \n",
       "75                              NaN                               NaN   \n",
       "76                              NaN                               NaN   \n",
       "77                              NaN                               NaN   \n",
       "78                         7.375797                            1952.0   \n",
       "79                              NaN                               NaN   \n",
       "80                              NaN                               NaN   \n",
       "81                              NaN                               NaN   \n",
       "82                              NaN                               NaN   \n",
       "83                              NaN                               NaN   \n",
       "84                         7.375797                            1952.0   \n",
       "85                              NaN                               NaN   \n",
       "86                              NaN                               NaN   \n",
       "87                              NaN                               NaN   \n",
       "88                              NaN                               NaN   \n",
       "89                              NaN                               NaN   \n",
       "90                         7.375797                            1952.0   \n",
       "91                              NaN                               NaN   \n",
       "92                              NaN                               NaN   \n",
       "93                              NaN                               NaN   \n",
       "94                              NaN                               NaN   \n",
       "95                              NaN                               NaN   \n",
       "\n",
       "                                                 Type Percent Editing  \n",
       "0               wt_cut1_total_reads_collapsed_percent        0.000000  \n",
       "1               wt_cut1_total_reads_collapsed_percent             NaN  \n",
       "2               wt_cut1_total_reads_collapsed_percent             NaN  \n",
       "3               wt_cut1_total_reads_collapsed_percent             NaN  \n",
       "4               wt_cut1_total_reads_collapsed_percent             NaN  \n",
       "5               wt_cut1_total_reads_collapsed_percent             NaN  \n",
       "6               wt_cut2_total_reads_collapsed_percent       17.879098  \n",
       "7               wt_cut2_total_reads_collapsed_percent             NaN  \n",
       "8               wt_cut2_total_reads_collapsed_percent             NaN  \n",
       "9               wt_cut2_total_reads_collapsed_percent             NaN  \n",
       "10              wt_cut2_total_reads_collapsed_percent             NaN  \n",
       "11              wt_cut2_total_reads_collapsed_percent             NaN  \n",
       "12  large_deletion_cut1_total_reads_collapsed_percent       29.149590  \n",
       "13  large_deletion_cut1_total_reads_collapsed_percent             NaN  \n",
       "14  large_deletion_cut1_total_reads_collapsed_percent             NaN  \n",
       "15  large_deletion_cut1_total_reads_collapsed_percent             NaN  \n",
       "16  large_deletion_cut1_total_reads_collapsed_percent             NaN  \n",
       "17  large_deletion_cut1_total_reads_collapsed_percent             NaN  \n",
       "18  large_inversion_cut1_total_reads_collapsed_per...        0.000000  \n",
       "19  large_inversion_cut1_total_reads_collapsed_per...             NaN  \n",
       "20  large_inversion_cut1_total_reads_collapsed_per...             NaN  \n",
       "21  large_inversion_cut1_total_reads_collapsed_per...             NaN  \n",
       "22  large_inversion_cut1_total_reads_collapsed_per...             NaN  \n",
       "23  large_inversion_cut1_total_reads_collapsed_per...             NaN  \n",
       "24  large_inversion_cut2_total_reads_collapsed_per...        9.375000  \n",
       "25  large_inversion_cut2_total_reads_collapsed_per...             NaN  \n",
       "26  large_inversion_cut2_total_reads_collapsed_per...             NaN  \n",
       "27  large_inversion_cut2_total_reads_collapsed_per...             NaN  \n",
       "28  large_inversion_cut2_total_reads_collapsed_per...             NaN  \n",
       "29  large_inversion_cut2_total_reads_collapsed_per...             NaN  \n",
       "..                                                ...             ...  \n",
       "66  doner_head_head_cut1_total_reads_collapsed_per...        0.000000  \n",
       "67  doner_head_head_cut1_total_reads_collapsed_per...             NaN  \n",
       "68  doner_head_head_cut1_total_reads_collapsed_per...             NaN  \n",
       "69  doner_head_head_cut1_total_reads_collapsed_per...             NaN  \n",
       "70  doner_head_head_cut1_total_reads_collapsed_per...             NaN  \n",
       "71  doner_head_head_cut1_total_reads_collapsed_per...             NaN  \n",
       "72           1a_1a_cut1_total_reads_collapsed_percent        0.000000  \n",
       "73           1a_1a_cut1_total_reads_collapsed_percent             NaN  \n",
       "74           1a_1a_cut1_total_reads_collapsed_percent             NaN  \n",
       "75           1a_1a_cut1_total_reads_collapsed_percent             NaN  \n",
       "76           1a_1a_cut1_total_reads_collapsed_percent             NaN  \n",
       "77           1a_1a_cut1_total_reads_collapsed_percent             NaN  \n",
       "78           2b_2b_cut1_total_reads_collapsed_percent        0.000000  \n",
       "79           2b_2b_cut1_total_reads_collapsed_percent             NaN  \n",
       "80           2b_2b_cut1_total_reads_collapsed_percent             NaN  \n",
       "81           2b_2b_cut1_total_reads_collapsed_percent             NaN  \n",
       "82           2b_2b_cut1_total_reads_collapsed_percent             NaN  \n",
       "83           2b_2b_cut1_total_reads_collapsed_percent             NaN  \n",
       "84  target_plus_plasmid_total_reads_collapsed_percent        0.000000  \n",
       "85  target_plus_plasmid_total_reads_collapsed_percent             NaN  \n",
       "86  target_plus_plasmid_total_reads_collapsed_percent             NaN  \n",
       "87  target_plus_plasmid_total_reads_collapsed_percent             NaN  \n",
       "88  target_plus_plasmid_total_reads_collapsed_percent             NaN  \n",
       "89  target_plus_plasmid_total_reads_collapsed_percent             NaN  \n",
       "90         plasmid_only_total_reads_collapsed_percent        4.508197  \n",
       "91         plasmid_only_total_reads_collapsed_percent             NaN  \n",
       "92         plasmid_only_total_reads_collapsed_percent             NaN  \n",
       "93         plasmid_only_total_reads_collapsed_percent             NaN  \n",
       "94         plasmid_only_total_reads_collapsed_percent             NaN  \n",
       "95         plasmid_only_total_reads_collapsed_percent             NaN  \n",
       "\n",
       "[96 rows x 187 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pivot = melt_results(results_summary_with_experiments)\n",
    "results_pivot.to_excel(os.path.join(directory, 'results_summary_pivot.xlsx'))\n",
    "results_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
